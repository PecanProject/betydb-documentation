[
["about-betydb-database-description-and-users-guide.html", "1 About BETYdb: Database Description and User’s Guide 1.1 Objectives 1.2 Scope 1.3 Content 1.4 Design 1.5 Data Entry 1.6 Software 1.7 List of Tables in the BETY Database", " 1 About BETYdb: Database Description and User’s Guide This wiki describes the purpose, design, and use of the Biofuel Ecophysiological Traits and Yields database (BETYdb). BETYdb is a database of plant trait and yield data that supports research, forecasting, and decision making associated with the development and production of cellulosic biofuel crops. While the content of BETYdb is agronomic, the structure of the database itself is general and can therefore be used more generally for ecosystem studies. Note that this document does not cover the suite of tables used by PEcAn. These are covered in the PEcAn documentation. 1.1 Objectives A major motivation of the biofuel industry is to reduce greenhouse gas emissions by providing ecologically and economically sustainable sources of fuel, thereby reducing dependence on fossil fuel. The goals of this database are to provide a clearinghouse of existing research on potential biofuel crops; to provide a source of data on plant ecophysiological traits and yields; and to present ecosystem-scale re-analysis and forecasts that can support the agronomic, ecological, policy, and economic aspects of the biofuel industry. This database will facilitate the scientific advances and assessments that the transition to biofuels will require. The objectives of this database are to allow other users access to data that has been collected from previously published and ongoing research in a consistent format, and to provide a streamlined interface that allows users to enter their own data. These objectives will support specific research and collaboration, advance agricultural practices, and inform policy decisions. Specifically, BETYdb supports the following uses, allowing users to: Carry out statistical analyses to explore the relationships between traits Identify differences among species and functional groups Access BETYdb from simulation models to look up values for traits and parameters Identify gaps in knowledge about biofuel crop traits and model parameters to aid rational planning of research activities BETYdb provides a central clearinghouse of biofuel crop physiological traits and yields in a consistently organized framework that simplifies the use of these data for further analysis and interpretation. Scientific applications include the development, assessment, and prediction of crop yields and ecosystem services in biofuel agroecosystems. The database directly supports parameterization and validation of ecological, agronomic, engineering, and economic models. The initial target end-users of BETYdb version 1.0 are users within EBI who aim to support sustainable biofuel production through statistical analysis and ecological modeling. By streamlining the process of data summary, we hope to inspire new scientific perspectives on biofuel crop ecology that are based on a comprehensive evaluation of available knowledge. All public data in BETYdb is made available under the Open Data Commons Attribution License (ODC-By) v1.0. You are free to share, create, and adapt its contents. Data in tables having an an access_level column and in rows where the access_level value is 1 or 2 are not covered by this license but may be available for use with consent. Please cite the source of data as: LeBauer, David; Dietze, Michael; Kooper, Rob; Long, Steven; Mulrooney, Patrick; Rohde, Gareth Scott; Wang, Dan; (2010): Biofuel Ecophysiological Traits and Yields Database (BETYdb); Energy Biosciences Institute, University of Illinois at Urbana-Champaign. http://dx.doi.org/10.13012/J8H41PB9 1.2 Scope The database contains trait, yield, and ecosystem service data. Because all plants have the potential to be used as biofuel feedstock, BETYdb supports data from all plant species. In practice, the species included in the database reflect available data and the past and present research interests of contributors. Trait and yield data are provided at the level of species, with cultivar and clone information provided where available. The yield data not only includes end-of-season harvestable yield, it also includes measurements made over the course of the growing season. These yield data are useful in the assessment of historically observed crop yields, and they can also be used in the validation of plant models. Yield data includes peak biomass, harvestable biomass, and the biomass of the crop throughout the growing season. The trait data represent phenotypic traits; these are measurable characteristics of an organism. The primary objective of the trait data is to allow researchers to model second generation biofuel crops such as miscanthus and switchgrass. In addition, these data enable evaluation of new plant species as potential biofuel crops. Ecosystem service data reflect ecosystem-level observations, and these data are included in the traits table. 1.3 Content BETYdb includes data obtained through extensive literature review of target species in addition to data collected from the Energy Farm at the University of Illinois, and by our collaborators. The BETYdb database contains trait and yield data for a wide range of plant species so that it is possible to estimate the distribution of plant traits for broad phylogenetic groups and plant functional types. BETYdb contains data from intensive efforts to find data for specific species of interest as well as from previous plant trait and yield syntheses and other databases. Most of the data currently in the database is from plant genera that are the focus of our current and previous research. These species include perennial grasses such as miscanthus (Miscanthus sinensis), switchgrass (Panicum virgatum), and sugarcane (Saccharyn spp.). BETYdb also includes short-rotation woody species, including poplar (Populus spp.) and willow (Salix spp.) and a group of species that are being evaluated at the energy farm as novel woody crops. In addition to these herbaceous species, we are collecting data from a species in an experimental low-input, high-diversity prairie. An annotated, interactive database schema can be accessed on the BETYdb website by selecting “Docs –&gt; Schema”.1 1.4 Design BETYdb is a relational database that comprehensively documents available trait and yield data from diverse plant species (Figure 2.1). The underlying structure of BETYdb is designed to support meta-analysis and ecological modeling. A key feature is the PFT (plant functional type) table which allows a user to group species for analysis. On top of the database, we have created a web-portal that targets a larger range of end users, including scientists, agronomists, foresters, and those in the biofuel industry. 1.5 Data Entry The Data Entry Workflow provides a complete description of the data entry process. BETYdb’s web interface has been developed to facilitate accurate and efficient data entry. This interface provides logical workflow to guide the user through comprehensively documenting data along with species, site information, and experimental methods. This workflow is outlined in the BETYdb Data Entry Workflow document. Data entry requires a login with Create permissions; this can be obtained by contacting David LeBauer. 1.6 Software The BETYdb was originally developed in MySQL and later converted to PostgreSQL. It uses Ruby on Rails for its web portal and is hosted on a RedHat Linux Server (ebi-forecast.igb.illinois.edu). BETYdb is a relational database designed in a generic way to facilitate easy implementation of additional traits and parameters. 1.7 List of Tables in the BETY Database An up-to-date list of the tables in BETYdb along with their descriptions and diagrams of their interrelationships may be found at https://www.betydb.org/schemas. 2 Not all of the columns intended as foreign keys are marked as such in the SQL schema. Thus some lines (and even some tables) may be missing from the schema diagram.↩ More comprehensive documentation of the schema may be found at https://www.betydb.org/db_docs/index.html. The software used to produce this documentation, SchemeSpy, unfortunately does not document PostgreSQL check constraints. Also note that row counts in this document are not, in general, completely up-to-date. The complete, definitive documentation of the schema is the PostgreSQL code used to produce it, which may be found at https://github.com/PecanProject/bety/blob/master/db/structure.sql. Some background information about intended constraints may be found in the spreadsheet at https://docs.google.com/spreadsheets/d/1fJgaOSR0egq5azYPCP0VRIWw1AazND0OCduyjONH9Wk/edit?pli=1#gid=956483089 and in a PDF document viewable and downloadable at https://www.overleaf.com/2086241dwjyrd. These two documents are not necessarily up-to-date, and not all of the constraints mentioned in them have been implemented. In some instances, constraints on new data have been imposed at the application level but have not yet been imposed on the database itself because of violations in existing data.↩ "],
["betydb-tables.html", "2 BETYdb Tables 2.1 Schema: Enhanced Entity-Relationship Model 2.2 Tables 2.3 Table and field naming conventions", " 2 BETYdb Tables 2.1 Schema: Enhanced Entity-Relationship Model Figure 2.1: Abbreviated schema for BETYdb, focusing on tables used to store plant trait and yield data. This figure excludes other tables used for PEcAn workflow system provenance and data management and for synchronizing independent instances of BETYdb across many servers. A complete and up-to-date interactive schema is published at https://www.betydb.org/schemas. 2.2 Tables BETYdb is designed as a relational database, somewhat normalized as shown in the structure diagram Figure 2.1. Each table has a primary key field, id, which serves as surrogate key, a unique identifier for each row in the table. Most tables have a natural key defined as well, by which rows can be uniquely identified by real-world attributes. In addition, most tables have a created_at and an updated_at column to record row-insertion and update timestamps, and the traits and yields tables each have a user_id field to record the user who originally entered the data. A complete list of tables along with short descriptions is provided in Table 2, and a comprehensive description of the contents of each table is provided below. Note: An up-to-date list of the tables in BETYdb along with their descriptions and diagrams of their interrelationships may be found at https://www.betydb.org/schemas. Table 2 Table Key Fields Contents Use Traits, Yields mean, n, variance estimate, date, time, site, citation, species, treatment Trait, yield, and ecosystem service data, including values and summary statistics. Stores primary,data Variables name, definition, units Definitions, description, units, and allowable ranges of specific traits and ecosystem, services contained in the database Defines primary,data, covariates, and priors Covariates variable, level Context required to interpret a particular data point—for example the time, temperature, or location of a measurement Contextual information necessary to interpret data Plant Functional Type name, definition, reference Context required to interpret a particular data point—for example the time, temperature, or location of a measurement Data synthesis, QA/QC Species scientific name USDA Plants database, amended with additional species and links to other tables within BETYdb Cultivars species, name, citation Specific genotype bred for cultivation Priors variable, citation, phylogeny, distribution Probability distributions that quantify knowledge of a variable in the absence of information at the level of functional type, species, or cultivar Stores expert knowledge; used in QA/QC and data analysis Treatments name, definition Qualitative descriptions of treatments described in the primary publication Categorize experimental treatments; permits reference to original publication Managements date, citation, type, level, units Quantitative record of management activities performed on all plots or specific experimental interventions Sites name, latitude, longitude Location and basic climate and soil information Citations author, year, title, DOI Unique reference for source of information, not necessarily published Used in many tables to independently record source of information that may come from multiple publications Entities parent, name Links related trait records Used to identify measurments made on the same unit of replication (e. g. leaf, plant, or plot) when information is available; used to “pivot” data from long to wide. 2.3 Table and field naming conventions Each table is given a name that describes the information that it contains. For example, the table containing trait data is called “traits”, the table containing yield data is “yields”, and so on. Each table also has a primary key; the primary key is always “id”, and the primary key of a specific table might be identified as “yields.id” . One table can reference another table using a foreign key; the foreign key is given a name using the singular form of the foreign table, an underscore, and “id”, e. g. “trait_id” or “yield_id”. In some cases, two tables can have multiple references to one another, known as a “many to many” or “m:n” relationship. For example, one citation may contain data from many sites; at the same time, data from a single site may be included in multiple citations. Such relationships use join tables (also known as “association tables” or “junction tables”). Join tables combine the names of the two tables being related. For example, the table used to link citations and sites is named citations_sites. These join tables have two foreign keys (citation_id and site_id in this example) which together uniquely identify a row of the table (and thus constitute a candidate key). (For various implementational reasons, these tables also have a surrogate key named id, but in general such a key is extraneous.) While foreign key columns are identified implicitly by the naming convention whereby such columns end with the suffix _id, foreign keys can be made explicit by imposing a foreign-key constraint at the database level. Such a constraint identifies the table and column which the foreign key refers to and in addition guaranties that a row with the required value exists. Thus, if there is a foreign-key constraint saying that the column yields.citation_id refers to citations.id, then if there is a row in the yields table where cititation_id = 9, there must also be a row in the citations table where id = 9. Explicit foreign keys show up in the schema documentation as an entry in the References column of the table listing and as a line between tables in the schema diagrams. 2.3.1 Data Tables The two data tables, traits and yields, contain the primary data of interest; all of the other tables provide information associated with these data points. These two tables are structurally very similar. 2.3.1.1 traits The traits table contains trait data. Traits are measurable phenotypes that are influenced by a plant’s genotype and environment. Most trait records presently in BETYdb describe tissue chemistry, photosynthetic parameters, and carbon allocation by plants. 2.3.1.2 yields The yields table includes aboveground biomass in units of Mg per ha. Biomass harvested in the fall and winter generally represents what a farmer would harvest, whereas spring and summer harvests are generally from small samples used to monitor the progress of a crop over the course of the growing season. Managements associated with yields can be used to determine the age of a crop, the fertilization history, the harvest history, and other useful information. 2.3.2 Auxillary Tables 2.3.2.1 sites Each site is described in the sites table. A site can have multiple studies and multiple treatments. Sites are identified and should be used as the unit of spatial replication; treatments are used to identify independent units within a site, and these can be compared to other studies at the same site with shared management. “Studies” are not identified explicitly, but independent studies can be identified via shared management entries at the same site. 2.3.2.2 treatments The treatments table provides a categorical identifier of a study’s experimental treatments, if any. Any specific information such as rate of fertilizer application should be recorded in the managements table. A treatment name is used as a categorical (rather than continuous) variable, and the name relates directly to the nomenclature used in the original citation. The treatment name does not have to indicate the level of treatment used in a particular treatment; if required for analysis, this information is recorded as a management. Each study includes a control treatment; when there is no experimental manipulation, the treatment is considered “observational” and listed as “control”. In studies that compare plant traits or yields across different genotypes, site locations, or other factors that are built in to the database, each record is associated with a separate cultivar or site so these are not considered treatments. For ambiguous cases, the control treatment is assigned to the treatment that best approximates the background condition of the system in its non-experimental state; for this reason, a treatment that approximates conventional agronomic practice may be labeled “control”. 2.3.2.3 managements The managements table provides information on management types, including planting time and methods, stand age, fertilization, irrigation, herbicides, pesticides, as well as harvest method, time and frequency. The managements and treatments tables are linked through the managements_treatments table. Managements are distinct from treatments in that a management is used to describe the agronomic or experimental intervention that occurs at a specific time and may have a quantity whereas treatment is a categorical identifier of an experimental group. Managements include actions that are done to a plant or ecosystem—for example the planting density or rate of fertilizer application. In other words, managements are the way a treatment becomes quantified. Each treatment can be associated with multiple managements. The combination of managements associated with a particular treatment will distinguish it from other treatments. Each management may be associated with one or more treatments. For example, in a fertilization experiment, planting, irrigation, and herbicide managements would be applied to all plots but the fertilization will be specific to a treatment. For a multi-year experiment, there may be multiple entries for the same type of management, reflecting, for example, repeated applications of herbicide or fertilizer. 2.3.2.4 covariates The covariates table is used to record one or more covariates associated with each trait record. Covariates generally indicate the environmental or experimental conditions under which a measurement was made. The definition of specific covariates can be found in the variables table. Covariates are required for many of the traits because without covariate information, the trait data will have limited value. The most frequently used covariate is the temperature at which some respiration rate or photosynthetic parameter was measured. For example, photosynthesis measurements are often recorded along with irradiance, temperature, and relative humidity. Other covariates include the size or age of the plant or plant part being measured. For example, root respiration is usually measured on fine roots, and if the authors define fine root as &lt; 2mm, the covariate root_diameter_max has a value of 2. 2.3.2.5 pfts The plant functional type (PFT) table pfts is used to group plants for statistical modeling and analysis. Each row in pfts contains a PFT that is linked to a set of species in the species table. This relationship requires the lookup table pfts_species. Alternatively, a PFT may be linked to a set of cultivars in the cultivars table via the cultivars_pfts lookup table. (A PFT can not comprise both cultivars and species.) Furthermore, each PFT can be associated with a set of trait prior probability distributions in the priors table. This relationship requires the lookup table pfts_priors. In many cases, it is appropriate to use a pre-defined default PFT (for example tempdecid is temperate deciduous trees). In other cases, a user can define a new PFT to query a specific set of priors or subset of species. For example, there is a PFT for each of the functional types found at the EBI Farm prairie. Such project-specific PFTs can be named using the binomial scheme projectname.pftname—for example, ebifarm.c4grass instead of simply c4grass. 2.3.2.6 variables The variables table includes definitions of different variables used in the traits, covariates, and priors tables. Each variable has a name field and is associated with a standardized value for units. The description field provides additional information or context about the variable. 2.3.3 Join Tables Join tables are required when each row in one table may be related to many rows in another table and vice-versa; this is called a “many-to-many” relationship. 2.3.3.1 citations_sites Because a single study may use multiple sites and multiple studies may use the same site, these relationships are tracked in the citation_sites table. 2.3.3.2 citations_treatments Because a single study may include multiple treatments and each treatment may be associated with multiple citations, these relationships are recorded in the citations_treatments table. 2.3.3.3 cultivars_pfts The cultivars_pfts table allows a many-to-many relationship between the pfts and cultivars tables. A PFT that is related to a set of cultivars may not also be related to one or more species (except indirectly, by virtue of its associated cultivars belonging to particular species). A database-level constraint ensures this. 2.3.3.4 managements_treatments It is clear that one treatment may have many managements, e. g. tillage, planting, fertilization. It is also important to note that any managements applied to a control plot should, by definition, be associated with all of the treatments in an experiment; this is why the many-to-many association table managements_treatments is required. 2.3.3.5 pfts_priors The pfts_priors table allows a many-to-many relationship between the pfts and priors tables. This allows each pft to be associated with multiple priors and each prior to be associated with multiple pfts. 2.3.3.6 pfts_species The pfts_species table allows a many-to-many relationship between the pfts and species tables. A PFT that is related to a set of species may not also be related to one or more cultivars (except perhaps indirectly, by virtue of the associated species having certain cultivars). A database-level constraint ensures this. "],
["deploying-a-production-copy-of-the-betydb-web-application.html", "3 Deploying a Production Copy of the BETYdb Web Application Installing and Configuring Ruby and Rails Code Loading the BETYdb Database Complete Apache and Passenger configuration Final Steps", " 3 Deploying a Production Copy of the BETYdb Web Application These instructions are specifically tailored to the task of setting up a new instance of BETYdb on a CentOS 7 machine. We assume the following are installed: Ruby Version Manager (RVM). Bundler Phusion Passenger Apache 2.2 or greater. PostgreSQL 9.4 or greater. PostGIS 2.1.0 or greater. Git 1.8.2.1 or greater. R 3.1.0 or greater.3 Graphviz dot version 2.2.1 or a version greater than 2.4. Java 1.8 or greater. nodejs and npm curl Your preferred editor. In addition, we assume: You have an account on the machine, and that account has sudo access. The PostgreSQL server is running and there is a machine user account called postgres with password-less (peer) access to all PostgreSQL databases. PostgreSQL has been configured so that all non-postgres database roles can log in to the PostgreSQL server using a password, both using a UNIX domain socket connection and using a connection to localhost over TCP/IP. Information about installing CentOS, adding users, installing the requisite software, and setting up and starting the PostgreSQL server is contained in various subsections below. IMPORTANT! In what follows, we use the following placeholder names to represent names that will vary with the installation: Operating system accounts: &lt;adminuser&gt; — the operating system account name for a user with complete sudo access &lt;betyappuser&gt; — the operating system account name for the user that will own this BETY app instance; generally, &lt;betyappuser&gt; should equal &lt;betyapp&gt;, but we distinguish them here for clarity Path names: &lt;betyapp&gt; — the name of the parent directory of the Rails root directory for the BETY app instance Database-related names: &lt;betydb&gt; — the name of the database this instance of the BETY app will use &lt;dbuser&gt; — the owner of database &lt;betydb&gt; &lt;dbpw&gt; — the password for database user &lt;dbuser&gt; For convenience, we generally leave off the angle brackets below as if these are the actual names that we will be using. In practice, sometimes the same name will be used for several of these; for example, often &lt;betyappuser&gt;, &lt;betyapp&gt;, &lt;betydb&gt;, &lt;dbuser&gt;, and &lt;dbpw&gt; will all be “bety”. Installing and Configuring Ruby and Rails Code Step 1: Log in to the deployment machine as an administrator This is the account we refer to as &lt;adminuser&gt; above. This user will need to have sudo permissions to do such tasks as adding a new user, deploying the BETYdb code base, editing the HTTPD configuration files, and starting and restarting the Web server. Step 2: Add a new user as the owner of the BETYdb instance It is recommended that each Rails app be run under its own user account. Use the following command to create the user:4 sudo useradd &lt;betyappuser&gt; Also, you may want to ensure this user has your SSH key installed: sudo mkdir -p ~betyappuser/.ssh touch $HOME/.ssh/authorized_keys sudo sh -c &quot;cat $HOME/.ssh/authorized_keys &gt;&gt; ~betyappuser/.ssh/authorized_keys&quot; sudo chown -R betyappuser: ~betyappuser/.ssh sudo chmod 700 ~betyappuser/.ssh sudo sh -c &quot;chmod 600 ~betyappuser/.ssh/*&quot; Step 3: Choose a location for the application code In this example, we’ll choose /var/www/betyapp as the parent directory for the Rails root directory, which we’ll call code. Step 4: Create the target parent directory and clone the BETYdb code from the GitHub repository: sudo mkdir -p /var/www/betyapp sudo chown betyappuser: /var/www/betyapp cd /var/www/betyapp sudo -u betyappuser -H git clone https://github.com/PecanProject/bety.git code Step 5: If you have not already done so, install the correct version of Ruby First cd to the Rails root directory: cd /var/www/betyapp/code If you haven’t installed any versions of Ruby using the Ruby Version Manager, you should get a warning that the required version of Ruby is not installed along with the command to run to install it. Go ahead and install this version. This command should have the form rvm install &quot;ruby-X.X.X&quot; where “ruby-X.X.X” matches the contents of the file .ruby-version. You can use rvm list to check that you have the correct version of Ruby installed, and rvm current to check that you have the correct version activated. The next several steps should be run as the app’s user (&lt;betyappuser&gt;). Step 6: Log in to the application’s user account and make sure you are in the Rails root directory: sudo -u betyappuser -H bash -l cd /var/www/betyapp/code You may get error about not being able to create a gemset, which you may ignore, but you should check that the correct version of Ruby is active: rvm current Step 7: Use the Bundler to install the application Gems: bundle install --deployment --without development test javascript_testing debug If the bundler fails to install the “pg” Gem, use the “bundle config” command to add an option as follows and then re-run the bundle install command:5 bundle config --local build.pg --with-pg-config=/usr/pgsql-9.4/bin/pg_config bundle install Step 8: Create a database configuration file To do this from the command line, just run cat &gt; config/database.yml &lt;&lt; EOF production: adapter: postgis encoding: utf-8 reconnect: false database: &lt;betydb&gt; pool: 5 username: &lt;dbuser&gt; password: &lt;dbpw&gt; EOF replacing the placeholders &lt;betydb&gt;, &lt;dbuser&gt;, and &lt;dbpw&gt; with whatever identifiers you chose to user for these entities. Step 9: Create a Rails application customization file The most important purpose of this file is to override the default site key so that your site will be more secure. First, generate a secret key using the command bundle exec rake secret Then run cat &gt; config/application.yml &lt;&lt; EOF production: rest_auth_site_key: &#39;&lt;secret key&gt;&#39; EOF where &lt;secret key&gt; is the result of the rake secret command. This is a minimal application configuration file. There are many other settings that may be used to customize the appearance of your site. See the sample file config/application.yml.template for details. At the very least, it is highly recommended to set the contact information appropriate for your site. Below, we show how to modify this file to enable the SchemaSpy documentation generator. Step 10: Compile Rails assets: bundle exec rake assets:precompile RAILS_ENV=production Important! If you are planning to deploy the BETYdb app to a sub-URI of your server name—to yourserver.com/suburi, say, instead of yourserver.com—then you need to set the RAILS_RELATIVE_URL_ROOT variable when precompiling: bundle exec rake assets:precompile RAILS_ENV=production RAILS_RELATIVE_URL_ROOT=/suburi Loading the BETYdb Database For this first step you should still be logged in as &lt;betyappuser&gt; and still be in the /var/www/betyapp/code directory. Step 11: Download the load.bety.sh script from the PEcAn repository: curl https://raw.githubusercontent.com/PecanProject/pecan/develop/scripts/load.bety.sh &gt; script/load.bety.sh chmod +x script/load.bety.sh Now exit the &lt;betyappuser&gt; account: exit You should now be back to the administrator account &lt;adminuser&gt; that you originally logged in to. Step 12: If you aren’t already there, cd to the application root directory: cd /var/www/betyapp/code Step 13: Log in as user postgres: sudo su postgres Step 14: Create a role and a database for the BETYdb app First start psql: psql Now run the CREATE ROLE and CREATE DATABASE commands in psql: CREATE ROLE dbuser WITH LOGIN CREATEDB NOSUPERUSER NOCREATEROLE PASSWORD &#39;dbpw&#39;; CREATE DATABASE betydb WITH OWNER dbuser; \\q Step 15: Run the load.bety.sh script: script/load.bety.sh -a postgres -c -d betydb -e -g -m &lt;localdb id number&gt; -o dbuser -r 0 Here, &lt;localdb id number&gt; is some integer that is unique to each database. See Distributed instances of BETYdb for further information. This will create the tables, views, indices, constraints, and functions required for BETYdb, replicating the database schema found on machine 0, the Energy Biosciences Institute server for BETYdb, whose BETYdb database schema is considered the “canonical” or “official” schema.6 (Other machines may have a slightly modified schema, so it is important to use the creation (-c) option only when the remote machine is machine 0.) The tables will all be empty except for the following: formats, machines, mimetypes, schema_migrations, spacial_ref_sys, and users. A guest user account (“guestuser”) will be added to the users table. This machine’s database contains the most extensive metadata, so you may want load the data from this machine, not just the database schema. To do so, run the above command without the “-e” option. Step 16: (Optional) Load data from another machine: script/load.bety.sh -a postgres -d betydb -m &lt;localdb id number&gt; -o dbuser -r &lt;remotedb id number&gt; This may be executed multiple times with different remote database id numbers. Again, consult Distributed instances of BETYdb to see what data sources are available. (If you used the -e option in the previous step but then decided you want the full data from machine 0 after all, you can chose &lt;remotedb id number&gt;=0.) Step 17: Exit the postgres user account: exit You should now once again be in the administrative account (&lt;adminuser&gt;) and in the BETYdb app’s root directory, /var/www/betyapp/code. Complete Apache and Passenger configuration Step 18: Check that the correct version of Ruby is enabled: rvm current This should be the version listed in the file .ruby-version Step 19: Find the path to the Ruby interpreter: passenger-config about ruby-command Use the location given in the resulting output as the value of path-to-ruby in the next step. Step 20: Configure the Apache Server Create a new Apache configuration file (call it, say, bety.conf) in the configuration directory /usr/httpd/conf.d and open it in an editor. Add the following contents to the file: 7 &lt;VirtualHost *:80&gt; ServerName yourserver.com # Tell Apache and Passenger where your app&#39;s &#39;public&#39; directory is DocumentRoot /var/www/betyapp/code/public PassengerRuby /path-to-ruby # Relax Apache security settings &lt;Directory /var/www/betyapp/code/public&gt; Allow from all Options -MultiViews SetEnv SECRET_KEY_BASE &lt;secret key&gt; # (Alternatively, put &quot;export SECRET_KEY_BASE=&lt;secret key&gt;&quot; in the .bash_profile file for user &lt;betyappuser&gt;.) # Uncomment this if you&#39;re on Apache &gt;= 2.4: #Require all granted &lt;/Directory&gt; &lt;/VirtualHost&gt; Here, replace yourserver.com with your server’s host name and replace /path-to-bety with the path found above using the passenger-config command. Also, replace &lt;secret key&gt; with some long, random word. You can generate a suitable value using the command bundle exec rake secret (As noted in the comment, this setting can be put in the environment of &lt;betyappuser&gt; instead of here in the server configuration file.) Note: If you want your app to be served at a sub-URI of your server name, say, yourserver.com/suburi, use the following configuration instead: &lt;VirtualHost *:80&gt; ServerName yourserver.com PassengerRuby /path-to-ruby Alias /suburi /var/www/betyapp/code/public &lt;Location /suburi&gt; PassengerBaseURI /suburi PassengerAppRoot /var/www/betyapp/code &lt;/Location&gt; &lt;Directory /var/www/betyapp/code/public&gt; Allow from all Options -MultiViews SetEnv SECRET_KEY_BASE &lt;secret key&gt; # Uncomment this if you&#39;re on Apache &gt;= 2.4: #Require all granted &lt;/Directory&gt; &lt;/VirtualHost&gt; Step 21: Restart Apache: sudo apachectl restart Step 22: Test: curl yourserver.com or, if you deployed to a suburi, curl yourserver.com/suburi Alternatively, try visiting the URL in a browser. Final Steps Step 23: Create a BETYdb administrative account In a browser, visit the home page of your new BETYdb site and click the “Register for BETYdb” button. Fill out the form; at a minimum, you must supply values for “Login”, “Email”, “Password”, and “Confirm Password” and click the “I’m not a robot” checkbox. It is highly recommended to fill out the “Name” field as well since this is the name that will be displayed when you are logged in as the new user. Note that you cannot re-use a previously used login or e-mail address. After completing the form, click “Sign Up”. You should see the “Thanks for signing up!” message. Once you have created a user, give that user full access privileges. To do this, use psql: psql -U &lt;dbuser&gt; &lt;betydb&gt; Once psql has started, if the login of the user you wish to alter is “admin”, run these commands in the psql session: UPDATE users SET access_level = 1, page_access_level = 1 WHERE login = &#39;admin&#39;; \\q Step 24: Re-Set the Guest user account password The Guest User account password will not be set correctly unless you use ‘thisisnotasecret’ as the site key. But for security reasons, you shouldn’t use this as a site key on a production server (which was the reason for overriding the value of rest_auth_site_key in the customization file config/application.yml). So you need to reset the Guest User account’s password to get it to work again. Log in to BETYdb as the administrative user you created in the previous step and go to the Users list (menu item Data/Users). Search for “guestuser” and click the edit button for that user. Check the “change password” checkbox and then enter “guestuser” in both password fields; then click the “Update” button. Now log out and try the “Log in as Guest” button to make sure that it works. Step 25: Ensure images for Priors pages are generated BETYdb uses R to generate images for the Priors pages on the fly if they don’t already exist. In order for this to work, the ggplot2 R package must be installed. To do this, start up R using sudo R --vanilla Then, inside the R session, issue the command install.packages(c(&quot;ggplot2&quot;)) This will likely take a few minutes. To check that all is well, open the BETYdb app in a browser and navigate to the Data/Priors page. The images in the middle column should start being generated on the fly. Step 26: Ensure the SchemaSpy documentation can be generated SchemaSpy documentation is generated using Java. Two Jar files are needed, a PostgreSQL JDBC Driver file and a customized version of the SchemaSpy file. These need to be downloaded to a suitable location. By way of example, we’ll put them in /var/www/betyapp/code/lib/tasks/jar. To do this, first log in to the betyappuser account: sudo -u betyappuser -H bash -l Then run the following commands: cd /var/www/betyapp/code/lib/tasks mkdir jar cd jar wget https://www.dropbox.com/s/j50hk7cbqw7680u/schemaSpy.jar wget https://jdbc.postgresql.org/download/postgresql-42.2.4.jar Here, we use the latest JDBC Driver file as of this writing, postgresql-42.2.4.jar. Now, append to the config/application.yml configuration file as follows (be sure to use &gt;&gt; instead of &gt;): cat &gt;&gt; config/application.yml &lt;&lt; EOF schema_spy_settings: java_executable: java postgresql_driver_jar_file: lib/tasks/jar/postgresql-42.2.4.jar settings_for_customized_documentation: schema_spy_jar_file: lib/tasks/jar/schemaSpy.jar output_directory: . remove_root_dir_files: true EOF Run the rake task to generate the SchemaSpy documentation as follows: bundle exec rake bety:dbdocs RAILS_ENV=production Restart the Rails app with touch tmp/restart.txt and try visiting the database documentation in a browser by going to the URL for your running BETYdb instance and clicking the Schema menu item under the Docs menu. You should now have a fully-functional BETYdb instance. BETYdb will mostly run without R, dot, and Java. R is needed for generating preview images on the Priors pages. Java is needed in order to generate the database schema documentation, and dot is needed to generate diagrams for that documentation.↩ See the Phusion Passenger site’s instructions for installing Passenger here: https://www.phusionpassenger.com/library/walkthroughs/deploy/ruby/ownserver/apache/oss/el7/install_passenger.html↩ We don’t need to repeat all the options to bundle install that we used earlier because these options are “sticky”: they are stored in the bundle configuration file and will be used automatically until explicitly removed.↩ Unless otherwise noted, we use the word “schema” in its traditional sense, where it refers to the logical structure of a database, including the tables, views, functions, and integrity constraints it comprises. We are not using “schema” in its PostgreSQL-specific sense, where it refers to a namespace within a database.↩ If the Web site is to be served using SSL (Secure Sockets Layer), the virtual host directive should be &lt;VirtualHost *:443&gt;. Data providers that are particularly concerned about data security are advised to use SSL. If SSL is used, it is recommended to redirect calls to port 80 (http) to port 443 (https) using a directive such as the following: &lt;VirtualHost *:80&gt; ServerName yourserver.com Redirect permanent / https://yourserver.com &lt;/VirtualHost&gt; or, for suburi deployments, &lt;VirtualHost *:80&gt; ServerName yourserver.com Redirect permanent /suburi https://yourserver.com/suburi &lt;/VirtualHost&gt; This way, the site will always be served up securely.↩ "],
["setting-up-a-centos-server.html", "4 Setting Up a CentOS Server 4.1 Install CentOS 7 4.2 Install additional system software 4.3 Install required Ruby and Rails software8 4.4 Bundler: 4.5 node.js (needed to be able to compile Rails assets): 4.6 Phusion Passenger9", " 4 Setting Up a CentOS Server 4.1 Install CentOS 7 Download CentOS from https://www.centos.org/download/. The DVD ISO should have the essentials. Alternatively, you can use the NetInstall verion. Instructions are here: https://www.if-not-true-then-false.com/2014/centos-7-netinstall-guide/ 4.2 Install additional system software We assume you are logged in as a user with sudo privileges. The following commands will get you most of what’s needed: sudo -s yum install postgres yum install httpd yum install epel-release yum install http://yum.postgresql.org/9.4/redhat/rhel-7-x86_64/pgdg-centos94-9.4-3.noarch.rpm yum install postgresql94-server postgresql-contrib postgis2_94 postgresql94-devel yum install emacs # (or your favorite editor) yum install git yum install graphviz yum install R yum install java 4.3 Install required Ruby and Rails software8 4.3.1 RVM (Ruby Version Manager) Run the following three commands to get and install RVM and add yourself to the rvm group: sudo grgpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 curl -sSL https://get.rvm.io | sudo bash -s stable sudo usermod -a -G rvm `whoami` Ensure rvmsudo works: if sudo grep -q secure_path /etc/sudoers; then sudo sh -c &quot;echo export rvmsudo_secure_path=1 &gt;&gt; /etc/profile.d/rvm_secure_path.sh&quot; &amp;&amp; echo Environment variable installed; fi Log out of the server and then log back in to make RVM take effect. Install the correct version of Ruby First, visit https://github.com/PecanProject/bety/blob/master/.ruby-version and note the version of Ruby that BETYdb currently expects. To install that version of Ruby, run rvm install ruby-X.X.X where X.X.X is the version number found in the .ruby-version file. Ensure this version is set as the default by running rvm --default use ruby-2.3.0 4.4 Bundler: gem install bundler --no-rdoc --no-ri 4.5 node.js (needed to be able to compile Rails assets): sudo yum install -y epel-release sudo yum install -y --enablerepo=epel nodejs npm 4.6 Phusion Passenger9 Passenger requires EPEL. Enable it with the following commands: sudo yum install -y epel-release yum-utils sudo yum-config-manager --enable epel sudo yum clean all &amp;&amp; sudo yum update -y Ensure the date is working properly and install ntp if not: date If this gives the wrong output, install ntp: sudo yum install -y ntp sudo chkconfig ntpd on sudo ntpdate pool.ntp.org sudo service ntpd start Now add the Passenger YUM repository: sudo curl --fail -sSLo /etc/yum.repos.d/passenger.repo https://oss-binaries.phusionpassenger.com/yum/definitions/el-passenger.repo Install Passenger + Apache module: sudo yum install -y mod_passenger || sudo yum-config-manager --enable cr &amp;&amp; sudo yum install -y mod_passenger Restart Apache: sudo systemctl restart httpd Check installation: sudo /usr/bin/passenger-config validate-install See the Phusion Passenger site’s instructions for installing RVM, Ruby, Bundler, and nodejs here: https://www.phusionpassenger.com/library/walkthroughs/deploy/ruby/ownserver/apache/oss/install_language_runtime.html↩ See the Phusion Passenger site’s instructions for installing Passenger here: https://www.phusionpassenger.com/library/walkthroughs/deploy/ruby/ownserver/apache/oss/el7/install_passenger.html↩ "],
["configuring-postgresql.html", "5 Configuring PostgreSQL 5.1 Step 1: Initialize the database cluster and start the server 5.2 Step 2: Enable password authentication for all users other than postgres 5.3 Step 3: Create a new role and new database for BETYdb", " 5 Configuring PostgreSQL These instructions assume you have a fresh installation of PostgreSQL 9.4. Later versions can be used, but these instructions will have to be modified accordingly. 5.1 Step 1: Initialize the database cluster and start the server This may be done using the following commands: sudo -s # become &quot;root&quot; /usr/pgsql-9.4/bin/postgresql94-setup initdb systemctl enable postgresql-9.4 systemctl start postgresql-9.4 exit # leave the root account 5.2 Step 2: Enable password authentication for all users other than postgres As root or as user postgres, open pg_hba.conf (probably in /var/lib/pgsql/9.4/data) for editing. Find the line for local domain socket connections: # TYPE DATABASE USER ADDRESS METHOD local all all peer Change “peer” to “md5”. Also, add a line for user postgres directly above this one to allow peer authentication. Your file should now look like this: # TYPE DATABASE USER ADDRESS METHOD local all postgres peer local all all md5 Also, find the two lines for IPv4 and IPv6 local connections: # TYPE DATABASE USER ADDRESS METHOD # IPv4 local connections: host all all 127.0.0.1/32 ident # IPv6 local connections: host all all ::1/128 ident In both lines, change “ident” to “md5”. (This seems to be needed to run the schema-spy documentation generator tool.) Save and close the file. Now restart the PostgreSQL server so that the changes take effect: sudo systemctl restart postgresql-9.4 5.3 Step 3: Create a new role and new database for BETYdb By way of example, we’ll call the new role for BETYdb dbuser and give it password dbpw, and the BETYdb database will be called betydb. (See the note on placeholder names in the beginning section of Deploying a Production Copy of the BETYdb Web Application. Since user postgres (the only database role so far) uses peer authenication, we have to become that user to log in to the database: sudo su postgres Now start a psql session: psql In the psql session, run the following commands to create the new user and new database and then exit the session: CREATE ROLE dbuser WITH LOGIN CREATEDB NOSUPERUSER NOCREATEROLE PASSWORD &#39;dbpw&#39;; CREATE DATABASE betydb WITH OWNER dbuser; \\q "],
["archived-setup-documentation.html", "6 Archived Setup Documentation 6.1 Setting up a RedHat or CentOS Server 6.2 Instructions for Installing and Configuring PostgreSQL 6.3 Installing the BETYdb Rails Application", " 6 Archived Setup Documentation These pages are being kept temporarily for reference. Much of what is here is superceded by the preceding setup documentation. 6.1 Setting up a RedHat or CentOS Server 6.1.1 Overview BETYdb runs on RedHat, CentOS, Ubuntu and OSX; instructions for installing on these systems can be found in the PEcAn documentation. The original BETYdb (betydb.org) runs on a Red Hat Enterprise Linux version 5.8 Server. To simulate this environment, we have set up a CentOS 5.8 server at pecandev.igb.illinois.edu for testing. This documentation is aimed at installing BETYdb on a production RedHat, CentOS or similar operating system. These instructions have been tested and refined on our production (ebi-forecast.igb.illinois.edu) and development (pecandev.igb.illinois.edu) servers. See the Installing BETY section of the PEcAn documentation for more generic installation instructions. If you have any questions about installing BETYdb … please submit an issue or send an email. 6.1.1.1 Create an netinstall of the CentOS ISO 6.1.1.2 Boot from CD and Install Following instructions here: http://www.if-not-true-then-false.com/2010/centos-netinstall-network-installation/ Download this iso: http://vault.centos.org/5.8/isos/x86_64/CentOS-5.8-x86_64-netinstall.iso it is the “netinstall” version, small enough to fit on a CD, but requires internet to install burn to CD boot from CD ftp server: vault.centos.org directory: /centos/5.8/os/x86_64 6.1.1.3 Configuration Add new user adduser johndoe add user to root sudo su emacs /etc/sudoers add the line johndoe ALL=(ALL) ALL 6.1.1.4 Add new repository instructions here: http://www.rackspace.com/knowledge_center/article/installing-rhel-epel-repo-on-centos-5x-or-6x wget http://dl.fedoraproject.org/pub/epel/5/x86_64/epel-release-5-4.noarch.rpm sudo rpm -Uvh epel-release-5*.rpm … move to PEcAn documentation page for build environment https://pecanproject.github.io/pecan-documentation/master/pecan-setup.html#installing-bety Remember to install R 3.0: wget http://cran.us.r-project.org/src/base/R-3/R-3.0.1.tar.gz tar xzf R-3.0.1.tar.gz cd R-3.0.1 ./configure make sudo make install 6.1.1.5 Site data installation cd /usr/local/ebi rm -rf sites curl -o sites.tgz http://isda.ncsa.illinois.edu/~kooper/EBI/sites.tgz tar zxf sites.tgz sed -i -e &quot;s#/home/kooper/projects/EBI#${PWD}#&quot; sites/*/ED_MET_DRIVER_HEADER rm sites.tgz rm -rf inputs wget http://isda.ncsa.illinois.edu/~kooper/EBI/inputs.tgz tar zxf inputs.tgz rm inputs.tgz 6.1.1.6 Database Creation See the PEcAn documentation for additional information, e.g. on the scripts (load.bety.sh is in the PEcAn repo), running the rails and/or php front-ends # install database (code assumes password is bety) sudo -u postgres createuser -d -l -P -R -S bety sudo -u postgres createdb -O bety bety sudo -u postgres CREATE=YES REMOTESITE=0 scripts/load.bety.sh REMOTESITE=1 scripts/load.bety.sh Open up updatedb.sh and remove the two lines #change to home cd If these are left in, the script will attempt to put the site data in ~/sites instead of /usr/local/ebi/sites. #fetch and updates the bety database ./updatedb.sh 6.1.1.7 Ruby installation The version of ruby available through yum is too low, so we have to use rvm user$ \\curl -L https://get.rvm.io | sudo bash -s stable rvm install 1.9 rvm use 1.9 yum upgrade rubygem yum install mysql-devel.x86_64 yum install ImageMagick-devel.x86_64 yum install rubygem-rails yum install httpd-devel wget http://www.sqlite.org/2013/sqlite-autoconf-3071700.tar.gz tar -xzf sqlite-autoconf-3071700.tar.gz cd sqlite-autoconf-3071700.tar.gz ./configure make make install If you plan to run the JavaScript-based rspec tests, you will also need to install qt: wget http://download.qt-project.org/official_releases/qt/4.8/4.8.6/qt-everywhere-opensource-src-4.8.6.tar.gz tar -xf qt-everywhere-opensource-src-4.8.6.tar.gz cd qt-everywhere-opensource-src-4.8.6 ./configure --prefix=/usr/local/qt-4.8.6 make make install export PATH=/usr/local/qt-4.8.6/bin:$PATH export PATH=/usr/local/ruby-1.8.3/bin:$PATH # Before running the &quot;gem&quot; command, type &quot;gem environment&quot; and make sure the installation directory matches # the installation directory used by the BetyDB Rail application. If you are using RVM, it should suffice # simply to switch the the root directory of the application, e.g. &quot;cd /usr/local/ebi&quot;. gem install capybara-webkit Then all the ruby gems bety needs. cd /usr/local/bety gem install bundler bundle install # (If you didn&#39;t install qt and capybara-webkit, you will need to run &quot;bundle install --without test_js&quot; instead.) Configuration for Bety: cd /usr/local/ebi/bety # create folders for upload folders mkdir paperclip/files paperclip/file_names chmod 777 paperclip/files paperclip/file_names # create folder for log files mkdir log touch log/production.log chmod 0666 log/production.log touch log/test.log chmod 0666 log/test.log cat &gt; config/database.yml &lt;&lt; EOF production: adapter: mysql2 encoding: latin1 reconnect: false database: bety pool: 5 username: bety password: bety test: adapter: mysql2 encoding: latin1 reconnect: false database: test pool: 5 username: bety password: bety EOF # setup per-instance configuration cp config/application.yml.template config/application.yml # Be sure to edit the sample values in application.yml to provide values appropriate to your server. # In particular, the actual value for rest_auth_site_key needs to be replaced with one matching the DB you are using. # configure apache ln -s /usr/local/ebi/bety/public /var/www/bety cat &gt; /etc/apache2/conf.d/bety &lt;&lt; EOF RailsEnv production RailsBaseURI /bety &lt;Directory /var/www/bety&gt; Options FollowSymLinks AllowOverride None Order allow,deny Allow from all &lt;/Directory&gt; EOF You may have to change your DocumentRoot in /etc/httpd/conf/httpd.conf from “/var/www/html” to “/var/www” if you get the error message ‘Passenger error #2 An error occurred while trying to access’/var/www/html/bety’: Cannot resolve possible symlink ‘/var/www/html/bety’: No such file or directory (2)’. Up next make apache2 and passenger play nicely: rvmsudo passenger-install-apache2-module If that fails, try sudo -s source `rvm gemdir` Finally run the tests cd /usr/local/eby/bety/ bundle exec rake db:test:prepare &amp;&amp; bundle exec rake db:fixtures:load RAILS_ENV=test &amp;&amp; bundle exec rspec spec/ [Note: If you are using RVM version 1.11 or later, you can omit the “bundle exec” portion of all rake and rspec commands. For example, the command above could just be typed as rake db:test:prepare &amp;&amp; rake db:fixtures:load RAILS_ENV=test &amp;&amp; rspec spec/] 6.2 Instructions for Installing and Configuring PostgreSQL These instructions are for installation on Ubuntu. For other Linux-like systems, the steps are similar. Mainly the file locations and the installation command (apt-get here) will be different. Run sudo apt-get install postgresql. Create user bety: Run sudo -u postgres createuser -P bety. Type bety when prompted for a password. This is the default user the the BetyDB Rails application connects to the database as. [Optional:] If you wish to administer the database without switching to user postgres (so that you don’t have to prefix all your commands with sudo -u postgres) add yourself as a superuser: sudo -u postgres createuser -s &lt;your_ubuntu_login_name&gt;. This will allow you to run all PostgreSQL commands as yourself without a password. Edit the pg_hba.conf file to allow bety to log in using a password. On Ubuntu, this file is most likely located at /etc/postgresql/9.3/main/pg_hba.conf (assuming you are using version 9.3). In detail: sudo su # this allows accessing and editing the conf file cd /etc/postgresql/9.3/main cp pg_hba.conf pg_hba.conf-original # optional convenience if you need to start over emacs pg_hba.conf # use your favorite editor In this file, you will see a line like this local all all peer Assuming this is a fresh install of PostgreSQL, you can give password access to user bety by adding the line local bety bety md5 immediately before this. Then save the file. In order for the configuration to take effect, you must reload the config files: sudo /etc/init.d/postgresql reload You can test that user bety exists and can log in by running the following: sudo -u postgres createdb -O bety bety psql -U bety 6.2.0.1 Manually dumping and installing BETYdb In this example, we are dumping BETY from “betyhost” to “myserver” ssh betyhost pg_dump -U postgres bety &gt; bety_YYYYMMDD.sql rsync bety_YYYYMMDD.sql myserver: 6.2.0.1.1 Create Copy of BETY ssh myserver createdb -U postgres bety_copy 6.2.0.1.2 Enable PostGIS psql -U postgres postgres=# \\c bety_copy postgres=# CREATE EXTENSION POSTGIS; Also see Creating a new PostGIS-enabled database template. 6.2.0.1.3 Import database psql -U postgres bety_copy &lt; bety_YYYYMMDD.sql 6.3 Installing the BETYdb Rails Application Note: This guide is aimed at Rails developers and testers. If you are a Pecan developer, you may want to use the notes in the PEcAn documentation instead of or in addition to the notes below. quick start The install_pecan.sh script contains steps used to create a Virtual Machine on line 398 and dependencies for different OS’s on line 102 6.3.1 Prerequisites Git Ruby 2.1.5 (Anything later than version 1.9.3 will probably work, but 2.1.5 is the officially supported version.) If you are doing Rails development or if you are using Ruby for outside of BETYdb, you may want to install RVM so that you can easily switch between Rails versions and Gem sets. PostgreSQL with the PostGIS extension (see Instructions for Installing and Configuring PostgreSQL for information on installing and configuring PostgreSQL) Apache web server (optional; developers in particular can simply use the built-in Rails server) In addition, the scripts below assume you have a working Bash shell. (Windows users might be able to use Cygwin or some other some other port of Linux tools.) 6.3.2 Installing the Rails Application 6.3.2.1 Installing the Rails code and Ruby Gems Run these commands to get the Rails code and the Ruby Gems that it uses: # This can be any place you have write permissions for, probably something under your home directory: INSTALLATION_DIRECTORY=~/projects # install bety cd $INSTALLATION_DIRECTORY # Developers who will be submitting Git pull requests should make a fork of bety.git on GitHub and then # replace the URL below with the address of their own copy: git clone https://github.com/PecanProject/bety.git # install gems cd bety gem install bundler # not needed if you already have bundler bundle install # Use the --without option to avoid installing certain groups of Gems; see below. exit [Note: If you can’t or don’t wish to install the capybara-webkit gem, you can comment it out in the Gemfile before running bundle install. Note: If you receive “checking for pg_config… no” and the associated errors then you may need update build.pg using the “bundle config” command. For example, to update the bundle executable with the location of the pg_config command you can run: bundle config build.pg –with-pg-config=/usr/pgsql-9.4/bin/pg_config This assumes your pg_config is located at /usr/pgsql-9.4/bin/. Update this path as necessary for your local PostgreSQL/Postgis install] 6.3.2.1.1 Minimizing Gem Installation Certain Ruby Gems are difficult or time-consuming to install on certain platforms, and if they are not essential to your work, you may wish to avoid installing them. (If this isn’t a concern, you may skip this section.) If you look at the Gemfile in the root directory of the BETYdb Rails code, you will see the certain Gems are specified within group blocks; this means they are intended to be used only in certain contexts. If you don’t intend to use BETYdb within those contexts, you may safely use the --without option to bundle install to exclude the Gems used only in those contexts. As an example, the passenger Gem is used only in the production environment. Therefore, it is in a production group within the Gemfile. If you run bundle install --without=production the bundler will skip installation of passenger. Moreover, this is a “remembered” option: the next time you run bundle install, it will remember not to install production-only Gems even if you haven’t specified the --without option. Furthermore, this “remembered option” is also respected by WEBrick, the default Rails server, so it won’t complain that you didn’t install the passenger Gem. As another example, the capybara-webkit Gem is difficult and time-consuming to install on some platforms, and unless you are running the RSpec tests, you can do without it. (In fact, even if you are running RSpec tests, most of the tests don’t use capybara-webkit, and for those that do, you can either skip them or tell them to use selenium-webdriver instead.) capybara-webkit is in a group called javascript_testing, so to avoid installing it, run bundle install --without=javascript_testing To see what the remembered “without” options are, run bundle config You can also use bundle config to specify directly what groups Bundler should skip. For example, to tell Bundler to ignore all groups except the production group, pass a colon-separated list containing all of the other groups to bundle config --local without: bundle config --local without development:test:javascript_testing:debug To revert to installing everything when you run bundle install, remove the without setting from the configuration with bundle config --delete without 6.3.2.2 Configuring Rails Configure the BETYdb Rails application using the following commands: cd $INSTALLATION_DIRECTORY/bety # setup bety database configuration cat &gt; config/database.yml &lt;&lt; EOF development: adapter: postgis encoding: utf-8 reconnect: false database: bety pool: 5 username: bety password: bety EOF # Optional: Override some of the default configuration settings given in config/defaults.yml. cp config/application.yml.template config/application.yml # Read the comments in this file and set the variable values you are interested in; delete the other settings. 6.3.2.3 Installing the Database Note To join the distributed network of databases, see the chapter Distributed instances of BETYdb. In the script directory of the bety Rails installation, find and run the update-betydb.sh script: ./update-betydb.sh This script is a wrapper script for the script load.bety.sh from the Pecan project. The latter can be downloaded by running update-betydb.sh without options. Use the -h option for more information. 6.3.3 Updating / Syncing the database See instructions Updating the BETY database. 6.3.4 Starting the BETYdb Rails Web Application cd to the bety directory, the directory you cloned the Rails code to. Run rails s. You should now be able to visit the web application at http://localhost:3000. To log in, use Login: carya, Password: illinois 6.3.5 Logrotation To prevent the log files from growing to large it is recommended to use logrotation. This will rotate the logs (for example every week) and append .1 etc. to the logfiles. The following can be used on an Ubuntu system. Edit /etc/logrotate.conf and add the following snippet at the bottom (replacing /home/bety/bety with the actual path to the installation of bety): /home/bety/bety/log/*.log { daily missingok rotate 7 compress delaycompress notifempty copytruncate } Once this installed you can force a logrotate to happen (or wait till Sunday) by using: sudo /usr/sbin/logrotate -f /etc/logrotate.conf "],
["updating-betydb-when-new-versions-are-released.html", "7 Updating BETYdb When New Versions are Released 7.1 Updating the BETY database 7.2 Update the Rails app and schema 7.3 Load a fresh version of database", " 7 Updating BETYdb When New Versions are Released 7.1 Updating the BETY database A new system is in place which will allow you to update the BETY database without losing any local changes (this is still BETA though). See the section Distributed instances of BETYdb for details on updating a local database in a way that retains any local changes. If you are a BETYdb Ruby-on-Rails developer, you probably don’t care about losing changes to your copy of the BETY database. You probably just want a reasonably up-to-date copy that you can use to test code changes with. If so, you may use the script update-betydb.sh in the script directory. This is just a wrapper for load.bety.sh script that makes it easy to download that script (without having to download all of Pecan) and easy to run it with the options you probably want. Step for doing this are: Run script/update-bety.sh without options to download a copy of load.bety.sh. Run script/update-bety.sh -i to write a stock configuration file. This file will contain the following settings: export DATABASE=bety # update database &quot;bety&quot;; change this name as needed export CREATE=YES # completely overwrite the database you are updating with new content export FIXSEQUENCE=YES # needed for the CREATE option export USERS=YES # create a stock set of users of various permission levels to use when testing DO NOT RUN THIS IF YOU HAVE DATA IN YOUR DATABASE!!!!!!!!!!! The CREATE=YES WILL destroy all data in your database Run script/update-bety.sh again with no options. This will read the config file you just created and use the settings to update your database copy. 7.2 Update the Rails app and schema If you have an instance of BETY and you might want to update it to the latest version at certain points for the following reasons. security updates new functionality importing data and remote server has newer version To update BETY you can use the following steps to update your system (this is assuming the VM, if you installed BETY in another location please change the path accordingly). This requires the development version of ruby. sudo -s # change to BETY cd /usr/local/bety # update BETY to latest version git pull # install all required gems bundle install --without test # update database RAILS_ENV=&quot;production&quot; rake db:migrate # restart BETY touch tmp/restart.txt At this point your database should have migrated to the latest version and the BETY application should have restarted. 7.3 Load a fresh version of database See the section of Updating BETY database above that pertains to BETYdb Ruby-on-Rails developers. "],
["distributed-instances-of-betydb.html", "8 Distributed instances of BETYdb 8.1 Syncing Databases 8.2 Feedback Tab 8.3 Customization 8.4 Issues", " 8 Distributed instances of BETYdb 8.1 Syncing Databases 8.1.1 Exporting Data The dump.bety.sh script does the following: dumps all data except: traits or yields where access_level &lt; 3 or checked = -1 runs and workflows contents (After implementing benchmarking, we will need to dump reference runs.) anonymizes users sets user1 to carya/illinois with access_level =1, page_access_level = 1, other users get access_level = 3, page_access_level = 4. Users id’s are preserved in order to allow admin to identify issues that are uncovered in anonymized version of db. Output: schema as .sql file, named after the most recent value in migrations table, to ensure that the data can be loaded (schema versions must match in order to sync) each table exported as a csv file, and tar-zipped. (psql function ‘’) 8.1.2 Importing Data You can sync a local instance of the BETYdb database with other instances. The load.bety.sh script will import data from other servers. MYSITE=X REMOTESITE=Y load.bety.sh This will set the number range based on the MYSITE variable (1,000,000,000 × MYSITE) to ((1,000,000,000 × (MYSITE + 1)) - 1) 8.1.3 Primary Key Allocations Assigning a unique set of primary key values to each instance of BETYdb allows each distributed system to create new records that can later be shared, and to import new records from other databases. Ranges with no server listed are reserved but may not be deployed or are used offline. Any changes to existing records should be done on the server that owns that record. Institution server url id allocated primary key values Energy Biosciences Institute / University of Illinois ebi-forecast.igb.illinois.edu https://betydb.org 0 1-1,000,000,000 Boston University psql-pecan.bu.edu https://psql-pecan.bu.edu/bety 1 1,000,000,001-2,000,000,000 Brookhaven National Lab modex.bnl.gov https://modex.bnl.gov/bety 2 2,000,000,001-3,000,000,000 Purdue bety.bio.purdue.edu http://bety.bio.purdue.edu/ 3 3,000,000,001-4,000,000,000 Virginia Tech 4 4,000,000,001-5,000,000,000 University of Wisconsin tree.aos.wisc.edu http://tree.aos.wisc.edu:6480/bety 5 5,000,000,001-6,000,000,000 TERRA Ref 141.142.209.94 https://terraref.ncsa.illinois.edu/bety 6 6,000,000,001-7,000,000,000 TERRA test 141.142.209.95 https://terraref.ncsa.illinois.edu/bety-test 7 7,000,000,001-8,000,000,000 TERRA MEPP UIUC terra-mepp.illinois.edu https://terra-mepp.illinois.edu/bety 8 8,000,000,001-9,000,000,000 University of Arizona 9 9,000,000,001-10,000,000,000 Ghent 10 10,000,000,001 - 11,000,000,000 Development / Virtual Machine localhost https: //localhost:6480/bety 99 99,000,000,000-a zillion 8.2 Feedback Tab New users and ‘feedback tab’ submissions are sent to all users with Admin privileges (gh-56). 8.3 Customization As of BETYdb v 4.1.3 it is possible to customize the user interface with project-specific design elements including. To do this, it is necessary to create a new file called config/application.yml. Details are in config/application.template.yml. See also https://github.com/PecanProject/bety/issues/368). Customizable elements include: Database name and descriptions Images found on the home page Sponsor logos and links in footer Database citation and data use policy Contact information 8.4 Issues to get latest data, have to query each server (or can get full dump from one server, but this is as out of date as the last sync) to edit data from records owned by another server, must edit on that server (or risk loosing this on next update) "],
["ruby-on-rails-application-overview-draft.html", "9 Ruby on Rails Application Overview (draft) 9.1 Introduction to Ruby-on-Rails 9.2 Introduction to MVC 9.3 Source Code Map 9.4 Misc. Information", " 9 Ruby on Rails Application Overview (draft) This is a Draft 9.1 Introduction to Ruby-on-Rails 9.2 Introduction to MVC 9.3 Source Code Map 9.4 Misc. Information 9.4.1 Providing model output for download Access to download model output is in app/views/maps/locations_yields.html.erb 9.4.2 Related Issues / Commits: https://github.com/PecanProject/bety/commit/7b7d56fdf4c577fa14d65fcf81c677f5a4bf0633 "],
["ruby-on-rails-developing-upgrading-and-deploying.html", "10 Ruby-on-Rails: Developing, Upgrading, and Deploying 10.1 Development and Testing 10.2 Deploying a new version: 10.3 Deploying or upgrading to a new version of the BETYdb Rails app 10.4 Versioning and Tagging 10.5 Commenting in the Rails Models", " 10 Ruby-on-Rails: Developing, Upgrading, and Deploying 10.1 Development and Testing Testing is an integral part of releasing a new version of the BETYdb Rails app. Developers should test prospective code on their development machines prior to submitting a pull request, and code managers should re-test the code before accepting a pull request. See Automated Tests for complete testing instructions. 10.2 Deploying a new version: For up-to-date instructions on making a new release, see Issuing a New Release. At the end of each sprint (or set of sprints, or when ready to deploy a new version), the version should be tagged, and a “release” should be created. See the Release Notes Template page for a sample draft of release notes. (We use the terms “deploy” and “upgrade” roughly synonymously, but “deploy” connotes what code manager does when providing a new version of BETYdb to, say, the production server, and “upgrade” connotes what developers maintaining their own copies of BETYdb do to keep those copies up-to-date. Making a new “release” is part of the deployment process but is not part of the upgrade process for individual users. The instructions below are written mainly with the code manager in mind but are easily adapted to the needs of developers or maintainers of private copies of BETYdb.) 10.3 Deploying or upgrading to a new version of the BETYdb Rails app Here is an outline “script” for deploying a new version of BETYdb to the production server: cd /usr/local/ebi # or to the Rails root of the copy you are upgrading # Check the git status to be sure the copy is &quot;clean&quot;. # Generally there shouldn&#39;t be any modified files and you should be # on the master branch. # git status # Get the latest code from Github. # git pull # This is usually not necessary, but if there has been code checked in to the # master branch since the version to be released, you will have to back up to it. # Note that we tag releases AFTER deploying them, so we can&#39;t use the release tag # as the git reference. # # git checkout &lt;git reference to version being deployed&gt; # Check the gem bundle. # bundle check # If the the bundle contains uninstalled Gems, run this: # bundle install # Check for pending migrations. # RAILS_ENV=production bundle exec rake db:migrate:status # The RAILS_ENV setting can be omitted by individual developers who only want # to migrate their development databases. # If there ARE pending migrations, run them (see below). # Tell the server there is new code; you may want to run the automated tests # BEFORE restarting the Rails server. # touch tmp/restart.txt [Note: If you are using RVM version 1.11 or later, you can omit the “bundle exec” portion of all rake commands. For example, the command above could be typed as just RAILS_ENV=production rake db:version ] If you do not wish to install the test pieces you can run bundle install --without test. [Note: If you can’t or don’t wish to install the capybara-webkit gem, you can comment it out in the Gemfile. It is only needed for testing the RSpec tests and it is only needed for a few of them. To avoid running the tests that require it, run rspec with the “–tag ~js” option.] At this point, the site can be tested, both through the browser and by running the Automated Tests. [To do: write hints for running automated tests on production servers] reference: [protocol for pull requests, testing etc. were discussed in bety issue #48] 10.3.1 Running Migrations If new code requires database migrations, then the database should be dumped, and then the migrations should be run. As noted above, you can find out whether there are migrations pending by comparing the result of RAILS_ENV=production bundle exec rake db:version with the latest migration shown by ls db/migrate If migrations are required, dump the database and run the migrations: pg_dump ebi_production &gt; [some suitable directory]/ebi_production.psql # (Generally, after the dump file has been created, I rename it to include the timestamp # information in the file name: ebi_production_YYYYMMDDhhmm.psql. This way multiple dump # files can be stored in the same directory.) RAILS_ENV=production bundle exec rake db:migrate It is especially important to dump the database if any of the pending migrations will delete data! An up-to-date copy of db/production_structure.sql should be generated and checked in: RAILS_ENV=production bundle exec rake db:structure:dump git add db/production_structure.sql git commit git push It is recommended to run this (only!) on the production version, since it is the structure of the production database that we want to document. (That said, it is true that the pecandev and beta deployments of the BetyDB database should have precisely the same structure. But in case they do not, we want to capture what is actually be used live.) Note that we no longer use the schema.rb file (see bety issue #44). The structure.sql files allow for complete documentation of the database structure, including features that (by default) are not expressible in the schema.rb file. production_structure.sql is the canonical specification of the complete database schema, the schema which the Rails code is meant to be run against. 10.4 Versioning and Tagging 10.4.1 Protocol for defining and releasing versions During Sprint Merge pull requests into the master branch of PecanProject/bety as necessary (in order to avoid conflicts, preferably within one working day) . [to-do: clarify how we handle pre-releases and why they are necessary] Create a pre-release. This should include a list of key expected features to be implemented during the sprint. If critical bug fix is required on production server: Create a branch off of the currently-deployed master version. (If subsequent critical bug fixes are later needed, they can also go on this branch.) Apply the bug fix to the branch. Test on your development machine. Push the branch to PecanProject/bety. If time permits, pull the branch to pecandev, switch to the branch, do any necessary gem and database updates (see below) and test. Repeat the previous step on the production server’s beta site. Repeat the previous step on the production server’s live site. The live server will now be on a branch until the next sprint release. If there were any database structure changes, regenerate the production_schema.sql file and commit it. Tag the currently-deployed version. [to-do: decide on a schema for versioning branch releases] Push the tag (and the new production_schema.sql file if it changed) to the repository. Before Sprint Review Merge any remaining pull requests into master. Deploy and test (see below) on pecandev.igb.illinois.edu:/usr/local/ebi Deploy and test on ebi-forecast.igb.illinois.edu:/usr/local/beta (for the sprint-review demo). After Sprint Review Revise pre-release based on features implemented during sprint. If any code changes were made after the sprint review, redeploy and test on pecandev and on ebi-forecast’s beta site. Deploy and test the latest master version on ebi-forecast.igb.illinois.edu:/usr/local/ebi Tag the published release. Ask David to post via the BETYdatabase account on Twitter add doi to release 10.4.2 Version Numbering We loosely follow semantic versioning. Any tag of the form betydb_x.x or betydb_x.x.x refers to a version that has been tested and deployed. Changes in the first or second digit of the version number mark some significant change. For example, the change to major version number 2.x marks the change to a new user interface. 10.5 Commenting in the Rails Models Example of a properly commented citation model ( /app/models/citations.rb ): https://gist.github.com/e68fea1baa070e68b984 And a properly commented covariates model ( /app/models/covariates.rb ): https://gist.github.com/5d0d96d7be1b1fd7b47c "],
["automated-tests.html", "11 Automated Tests 11.1 Development and Testing 11.2 Running the RSpec tests on BETYdb.", " 11 Automated Tests We use RSpec with Capybara for testing the BETYdb Rails application. If you are involved in changing code, you should run the entire test suite before submitting a pull request. If you discover a bug, you may wish to write a failing test that demonstrates the bug, one that will pass once the bug is fixed. 11.1 Development and Testing Testing is an integral part of releasing a new version of the BETYdb Rails app. Developers should test prospective code on their development machines prior to submitting a pull request, and code managers should re-test the code before accepting a pull request. See complete testing instructions below. 11.2 Running the RSpec tests on BETYdb. 11.2.1 Preparing the test database. [Note: The instructions below assume that the current Rails environment is development (the default). If you have set it to something else–for example, by running export RAILS_ENV=production (you might do this, for example, if you only run BETYdb in production mode and didn’t bother to set up a development environment or a development database)–modify these instructions accordingly.] If you haven’t yet done so, add the PostGIS extension to the default template database, template1. The simplest way to do this is to add the PostGIS extension to the template1 database template (psql -d template1 -c 'CREATE EXTENSION postgis'). This is needed because the test database is dropped and recreated every time you run the “prepare” task, and you want it to be created with the PostGIS extension so that tables that rely on it can be recreated. Alternatively, create a new template database that includes the PostGIS extension. (See below for instructions.) Go to the root directory of the copy of BETYdb that you are testing. Ensure Rails has a test database configuration: Open the file config/database.yml. It should have a section that looks something like test: adapter: postgis encoding: unicode reconnect: false database: test pool: 5 username: bety password: bety If it doesn’t, you can copy the section for development and then change the heading and the database specification to test. If you wish to use a template database other than the default (template1), also add a line of the form template: [your template name] Create the test database by running bundle exec rake db:test:prepare [Note: If you are using RVM version 1.11 or later, you can omit the “bundle exec” portion of all rake and rspec commands. For example, the command above could just be typed as rake db:test:prepare ] This will check for any pending migrations in the development database. If there are none, it will re-create the db/structure.sql file, create the database for the testing environment (“test” if you use the configuration listed above), and then create the tables, views, functions, etc. mentioned in the structure file. Note that we no longer use the schema.rb file (see https://github.com/PecanProject/bety/issues/44). The config.active_record.schema_format setting has been changed from :ruby to :sql to permit complete documentation of the database structure, including features that (by default) are not expressible in the schema.rb file. structure.sql is the canonical specification of the complete database schema for the last-released version of BETYdb; this is the schema which the latest release of the Rails code is meant to be run against. If there are pending migrations, run them (“bundle exec rake db:migrate”) and repeat the previous step. *Note: I found that I ran into permissions problems when attempting this step. To get around this, I started psql as a superuser and then ran “ALTER USER bety WITH SUPERUSER;” to make user bety a superuser as well. This shouldn’t be a security worry if you are just running tests on your own copy of BETYdb.] Populate the database from the fixtures: RAILS_ENV=test bundle exec rake db:fixtures:load (The fixtures are YAML files under test/fixtures.) 11.2.2 Running the tests The simplest way to run the tests is to simply run bundle exec rspec (or just rspec if you are using RVM &gt; 1.11) from the root directory of the copy BETYdb that you are testing. This will run all the tests under the “spec” directory. If you did not install capybara-webkit, you can run all the tests that do not need webkit support with the command bundle exec rspec --tag ~js This will skip all the tests that have the tag :js =&gt; true and run all the others. (See the Troubleshooting section below for an alternative to capybara-webkit for running tests that need a JavaScript driver.) Conversely, to run only the tests requiring capybara-webkit, use the command RAILS_ENV=test_js bundle exec rspec --tag js Note that if you are logging in remotely to run the tests, you will need an X-server running in order to run the tests requiring capybara-webkit! If you see the error webkit_server: cannot connect to X server this probably means you connected without the -X option. If you see the error webkit_server: Fatal IO error: client killed this probably means the X-server is no longer running. In either case, re-log in with an X-enabled connection. To run a specific file of tests, run bundle exec rspec path/to/testfile, optionally using the –tag option to skip certain tests. You can run a specific test in a file by appending a line number: bundle exec rspec path/to/testfile:line_number_of_first_line_of_test This command will appear under the “Failed examples” section of a test run (assuming the test failed); for example bundle exec rspec ./spec/features/management_integration_spec.rb:48 Some useful options to rspec are: –fail-fast: abort the run on first failure –format documentation (-fd for short): get nicely formatted output –backtrace (-b for short): get a full backtrace 11.2.3 Troubleshooting Sometimes it is useful to carry out a features test manually as a web site user. To do this, start up the rails server in the test environment using the command rails s -etest. Many or most of the features tests are written in such a way that you can figure out exactly what actions to carry out in order to mimic the test. Alternatively, use the the Selenium JavaScript driver in place of Capybara Webkit. The spec_helper file is set up to switch drivers automatically if you have set the environment variable RAILS_DEBUG=true. For example: RAILS_DEBUG=true bundle exec rspec -t js will run all your JavaScript-based tests using the Selenium JavaScript driver. As with Capybara Webkit, if you are logging in to a UNIX machine remotely in order to run the tests, you must have X11-forwarding in effect (use the -X option to your ssh command). Otherwise all of your Javascript-enabled tests will time out (but not for a full minute!) and then fail. With the Selenium JavaScript driver in place, each test having js: true in its opening line will be run by opening a copy of Firefox and replicating all of the actions specified in the test. If you wish to insert a break point at any point in the test so that you can see the state of the browser at that point, add the line binding.pry at the point at which you want to suspend the test. When running the test, pressing Ctrl-D at the command line will signal the test to continue. [Note: binding.pry will cause an error if your JavaScript driver is not Selenium. So if you switch back to running your test under Capybara Webkit, remove or comment out your breakpoints.] Note that even tests that don’t normally use a JavaScript driver can be debugged with Selenium–simply change the opening line. For example, if you change the opening line of a test from it &#39;should return &quot;Editing Citation&quot; &#39; do to it &#39;should return &quot;Editing Citation&quot; &#39;, js: true do the test will be run with a JavaScript driver (Selenium, if you set RAILS_DEBUG=true). Then you can add binding.pry breakpoint lines as needed and see the test in action. 11.2.4 Creating a new PostGIS-enabled database template As mentioned above, you must have a PostGIS-enabled database template set up in order for the rake db:test:prepare command to work. The easiest way to do this is to add the PostGIS extension to the default database template, which is called template. This can be done with the command psql -d template1 -c &#39;CREATE EXTENSION postgis&#39; But you may not want to do this, as this will cause all the databases you create to be PostGIS-enabled unless you explicitly specify a non-default template when you are creating them. So here is how to create a new PostGIS-enabled database template: Start psql and then run the following commands: CREATE DATABASE template_bety;. (You can name the template anything you like as long as it’s not the name of an existing database. Also, if you have made changes to template1 and want to ensure that template_bety is created from a “pristine” template, create it from template0: CREATE DATABASE template_bety TEMPLATE template0; ) \\c template_bety CREATE EXTENSION postgis; Change the owner of the newly-created table spacial_ref_sys to bety (or to the user whose username you specified in the “test” section of config/database.yml): ALTER TABLE spatial_ref_sys OWNER TO bety; This will avoid permissions problems when you try to load fixtures into your test database in the case where you haven’t made user bety a superuser. 1. UPDATE pg_database SET datistemplate = TRUE WHERE datname = 'template_bety'; 1. Finally, add the line template: template_bety to the test database section of your database.yml file. "],
["code-style.html", "12 Code Style 12.1 Whitespace conventions in the BETYdb Code 12.2 Fixing legacy formatting", " 12 Code Style 12.1 Whitespace conventions in the BETYdb Code We want to avoid introducing extraneous whitespace into our source files. There are two kinds of extraneous whitespace that you generally won’t see in your editor: Extra whitespace at the end of a line (“trailing whitespace”) Tab characters I call tab characters “extraneous whitespace” because if your editor shows tab characters as 4 spaces and my editor shows them as 8 spaces, I’m going to see a lot more whitespace than you are seeing, and the code alignment is going to look all wrong. In general, please do not use tabs in any Ruby code. (But if there are tabs already in the file before you start editing it, it may be best to leave them alone. See below.) Git has a built-in easy way to check your files for extraneous space before you commit them. Run the command: git diff --check If you’ve already staged the files you are about to commit, run git diff --cached --check These commands will find all trailing space and all tab characters that are preceded by a space characters. To catch other tab characters in your indentation, you will have to update your git configuration by running git config --add core.whitespace tab-in-indent Please do this! We don’t want any tab characters at all in the source files! (One possible exception: It is OK to have tab characters inside of a string literal.) You can also check for extraneous whitespace that you may have already committed. To check for extraneous whitespace in your last commit, run git diff --check HEAD^ In general, to check for extraneous whitespace commit since commit xyzabc, run git diff --check xyzabc You can combine this with the git merge-base command to find all of the whitespace you introduced since branching off of upstream/master: git diff --check $(git merge-base HEAD upstream/master) (If you local copy of master mirrors upstream/master, you can just use “master” in place of “upstream/master” here.) If you created your branch off your local master branch and haven’t changed your local master branch since then, you can just run git diff --check master Please always run some version of the “git diff –check” command before you submit a pull request! 12.2 Fixing legacy formatting Often when I’m coding, I’m tempted to “fix” the formatting of a file I’m working on. It’s generally easier to understand the code I’m working on if it is nicely indented to show the logical structure. But there is a drawback to reformatting code: If I want to run “git diff” to find out about the history of a file, I’m going to see a lot of differences I don’t care about if the file has been reformatted. And if I re-indent each line, commit the changes, and then run “git blame”, it’s going to look as though I am responsible for the latest change on each line. So here are my recommendations: If you have to work extensively with a file, and reformatting it will help you to understand the code better, then go ahead and reformat it. But if you do this, please: Look up and follow Rails code formatting guidelines (e.g., 2-space indentation levels, etc.) Devote a single commit to just reformatting–don’t include any “significant” code changes in that commit. This will make it easier to figure out the history of a file and what significant code changes were made to it. If you are only making minor changes to a file and don’t need to reformat the file to figure out what you are doing, just leave the existing formatting alone. Any new code you add, however, should follow good formatting conventions to the extent possible given that it may be surrounded by poorly-formatted code. "],
["complex-joins-in-the-web-interface.html", "13 Complex Joins in the Web Interface", " 13 Complex Joins in the Web Interface Several edit pages have sections for editing associations that use multi-select boxes with huge lists in them. These are being replaced by a search box the will display a list of of entities from the associated table and offer the user the opportunity toggle the “linked” status of each displayed entity–that is, unlink linked entities and link unlinked entities. Here is a list of files that need to be revised. We’ll call the primary table being edited “primary” and the associated table “associate”. primary_controller.rb _edit_primary_associate.html.erb routes.rb These files need to be added: _associate_tbody.html.erb search_associate.js.erb edit.js.erb add_primary_associate.js.erb rem_primary_associate.js.erb [Note: The convention for Rails join tables is to alphabetize the names, and this convention was also used in naming some of the templates and corresponding actions. To maintain this convention, some of the file names above should be altered if primary follows associate alphabetically. In this case, the file names to use will be edit_associate_primary.html.erb, add_associate_primary.js.erb, and rem_associate_primary.js.erb in place of the names given above, and the names of actions and references to these files in the files themselves will have to be adjusted accordingly.] Here are step-by-step instructions for making the required changes. The changes in place for editing sites associated with a citation may serve as a model (see the controller file citations_controller.rb and the template files in app/views/citations; in the case of the template files, these can simply be copied and a search and replace done to replace the primary and associated table names (use the singular form when doing this): Revise the _edit_primary_associate.html.erb partial (copy e.g. app/views/citations/_edit_citations_sites.html.erb and replace citation and site with the appropriate strings). Make the _associate_tbody.html.erb partial. Alter the routes.rb file, adding a member route of the form get :search_associate to the resources for primary. Add a search_associate.js.erb JavaScript template. Add a search (search_associate) action to the controller. If needed, add a search scope to the model for associate (or write the action in step 5 in a way so that one isn’t required). At this point searching associates on the edit page should work. (If needed, add an instance variable for the associated collection to the edit action.) Add an edit.js.erb Javascript template. Alter the edit action of the controller so that it handles js format. (render layout should be false, and additional template variables may have to be defined in the action.) Also, alter the update action to be ensure that if it renders the edit template on error, it has the variables it needs. At this point the “Show only related …” that appears after doing a search should be functional. In routes.rb, rename the :edit_primary_associate route to :add_primary_associate and change the method from post to get. Rename the corresponding action in the controller and revise this action (use CitationsController#add_citations_sites as a model). Add the add_primary_associate.js.erb JavaScript template. At this point, linking an associated entity to the primary entity by clicking on the + sign should work. In the controller, revise the rem_primary_associate action (use CitationsController#rem_citations_sites as a model). Add the rem_primary_associate.js.erb JavaScript template. At this point, unlinking an associated entity to the primary entity by clicking on the X should work. The “Update” link that appears next to the “Existing Sites Relationships” table caption after unlinking an associate should now work and should erase from view the entity you just unlinked. "],
["database-constraints.html", "14 Database Constraints 14.1 Types of Constraints 14.2 Value Constraints (including some NOT NULL constraints) 14.3 Foreign Key Constraints 14.4 Non Null Constraints 14.5 Uniqueness constraints 14.6 Technical Note", " 14 Database Constraints BETYdb contains database level constraints. Building constraints into the SQL schema provides a way of explicitly defining the meaning of the database model and its intended functionality. 14.1 Types of Constraints Value constraints include: range constraints on continuous variables “enum” constraints on, for example, state or country designations; this is a form of normalization (“US” and “USA” should be folded into a common designation); forms utilized by SELECT controls should perhaps be favored consistency constraints: for example (year, month, day) can’t be (2001, 2, 29); or the city, state, and country specified for a site should be consistent with the latitude and longitude; (this may be hard to check, but some level of checking may not be too difficult: for example, SELECT * FROM sites WHERE country IN ('US', 'United States', 'USA') AND lon &gt; 0; shouldn’t return any rows) Foreign key constraints Prevents accidental deletion of meta-data records in lookup tables Prevents entry of primary data without contextual information required to interpret the data Non-NULL constraints Constrains which fields can not be empty Uniqueness constraints These define what makes a row unique, by designating a ‘natural key’ - a combination of fields that make a row unique (distinct from primary keys that are used in cross-table joins). All constraints are defined in the database schema, db/structure.sql 14.2 Value Constraints (including some NOT NULL constraints) Global Text fields should not have leading or trailing white spaces. (Are there any fields for which this is not the case?) This can be checked with CHECK(TRIM(FROM &lt;columnname&gt;) = &lt;columnname&gt;) Probably sequences of two or more consecutive whitespace characters should be forbidden as well except for various free-form textual columns such as traits.notes. This can be checked with CHECK(REGEXP_REPLACE(TRIM(FROM &lt;columnname&gt;), ' +', ' ') = &lt;columnname&gt;) For convenience, we should probably define a function so we can just do something like CHECK(is_normalized(&lt;columnname&gt;)) . covariates: Check that level is in the range corresponding to variable referenced by variable_id. Check that n is positive (or &gt; 1 ?) if it is not NULL. Check that statname and stat are either both NULL or both non-NULL. (Alternatively, ensure that statname is non-NULL and that it equals the empty string if and only if stat is NULL.) Check that statname is one of “SD”, “SE”, “MSE”, “95%CI”, “LSD”, “MSD” or possibly “”. Consider creating an ENUM data type for this. managements: mgmttype: Constrain to one of the values in the web interface’s dropdown. (Is there any reason not to store these in the variables table, or in a separate lookup table? If we record units and range restrictions, this would be useful. On the other hand, if we continue to use a static list of management types, we should create a new ENUM type in the database to enumerate the allowed values. level: This should always be non-negative (except in the case that we want to use the special value -999 for mgmttypes where a level has no meaning; if so, we should also constrain level to be non-NULL). units: Should be constrained to a known set of values—in fact, on a per mgmttype basis; currently there are several varying designations for the same unit in a number of cases dateloc: Should be constrained to specific values. Since there is a value (9) designated as meaning “no data”, this column should be constrained to be NOT NULL. We should perhaps constraint this column to have this value if date is NULL. All values of citation_id in managements should also be associated with treatment via citations_treatments table. Does thie mean: The management should be associated with (at least) one of the treatments associated with the citation specified by citation_id? species: Ensure scientificname LIKE CONCAT(genus, ‘‘, species, ‘%’) Ensure genus is capitalized (and consists of a single word?). sites: lat (replaced by geometry) lon (replaced by geometry) som: 0 – 100 mat: range: -50, 150 masl: (replaced by geometry) map: Minimum is zero. Maximum = ? local_time: Range should be -12 to +12. This might more aptly be called timezone. A comment should clarify the meaning; I assume it should mean something like “the number of hours local standard time is ahead of GMT”. Some kind of check might be possible to ensure consistence with the longitude. sand_pct, clay_pct: These both have range 0–100, and sand_pct + clay_pct should be &lt;= 100. sitename: Unique and non-null (see below); also, ensure it does not have leading or trailing white space and no internal sequences of 2 or more consecutive spaces. This will make the uniqueness constraint more meaningful. (A similar white space constraint should apply to all textual keys in all tables.) traits: It isn’t clear what a natural key would be, but it would probably involve several foreign key columns. Perhaps (site_id, specie_id, cultivar_id, treatment_id, variable_id, and some combination of date and time fields. But it is important to have some sort of uniqueness constraint other than just the default unique-id constraint. For example, if the web-interface user accidentally presses the Create button on the New Trait page twice, two essentially equal trait rows will be created (they will differ only in the id and timestamp columns). See Uniqueness Constraints below! date, dateloc, time, timeloc, date_year, date_month, date_day, time_hour, time_minute: Check date and time fields consistency: For example, if dateloc is 91—97, date and date_year should both be NULL (but maybe old data doesn’t adhere to this?). If date_year, date_month, or date_day is NULL, date should be NULL as well. Also, dateloc and timeloc should be constrained to certain meaningful values. (See comment above on managements.dateloc.) mean: Check mean is in the range corresponding to the variable referenced by variable_id. n, stat, statname: n should always be positive; if n = 1, statname should be NULL. statname should be one of a specified set of values. (See comments above on covariates.stat and covariates.statname.) specie_id and cultivar_id need to be consistent with one another. access_level: Range is 1–4. treatments: name: Possibly standardize capitalization of names (easiest would be to have all words in all names not capitalized except for proper names and unit names where appropriate; this would convey the most information because (e.g.) author names would stand out from other words). This would need to be done manually to avoid converting proper names to lowercase. As stated below, names should be unique within a citation and site pair; standardizing capitalization will make this constraint more meaningful. definition: Treat captitalization similarly to that for names. control: There can be more than one control treatment per citation (currently there are). Below in the uniqueness section, it is stated that there can be only one control for a given citation and site. Since (as stated below) names should be unique within a citation and site pair, standardizing capitalization will make this constraint more meaningful. users: login: Enforce any constraints required by the Rails interface. email: Constrain to valid email addresses. country: Constrain to valid country names. area: This currently isn’t very meaningful. Perhaps this should be an ENUM. Alteratively, it could be constraint to be some category word followed by free-form text. access_level: Range is 1 - 4. page_access_level: Range is 1 - 4. postal_code: Ideally, this should be constrained according to the country. Since most users are (currently) from the U.S., we could at least constraint U.S. postal codes to “NNNNNN” or “NNNNNN-NNNN”. yields: [see also traits constraints] mean: mean should be in the range of plausible yield values. 14.3 Foreign Key Constraints All foreign key constraints follow the form table_id references tables, following Ruby style conventions. A Github Gist contains a list of foreign key constraints to be placed on BETYdb. The foreign keys are often named using the form fk_foreigntable_lookuptable_1 where the foreigntable has the foreign key. 14.4 Non Null Constraints This is a list of fields that should not be allowed to be null. In all cases, the primary key should not be null. For many-to-many relationship tables, the foreign keys should be non-null. citations: author, year, title covariates: trait_id, variable_id cultivars: specie_id, name dbfiles: file_name, file_path, container_type, container_id, machine_id ensembles: workflow_id formats: dataformat formats_variables: ? inputs: name, access_level, format_id likelihoods: run_id, variable_id, input_id machines: hostname managements: date, management_type methods: name, description, citation_id models: model_name, model_path, revision, model_type pfts: definition, name posteriors: pft_id, format_id priors: phylogeny, variable_id, distn, parama, paramb runs: model_id, site_id, start_time, finish_time, outdir, outprefix, setting, parameter_list, started_at, ensemble_id (note: finished_at will not be available when record is created) sites: lat, lon, sitename, greenhouse species: genus, species, scientificname traits: specie_id, citation_id, treatment_id, mean, variable_id, checked, access_level treatments: name, control users: login, name, email, crypted_password, salt, access_level, page_access_level, apikey variables: namem, units workflows: folder, started_at, site_id, model_id, hostname, params, advanced_edit, start_date, end_date yields: specie_id, citation_id, treatment_id, mean, variable_id, checked, access_level 14.5 Uniqueness constraints Uniqueness constraints are “natural keys”, i.e. combinations of fields that should be unique within a table. Ideally, each table would have a natural key, but a table may have 0, 1, or many uniqueness constraints. For many-to-many relationship tables, the foreign key pairs should be unique; these should be implemented but are not listed here for brevity. citations: author, year, title covariates: trait_id, variable_id cultivars: specie_id, name dbfiles: file_name, file_path, machine_id dbfiles: container_type, container_id formats_variables: ? formats: site_id, start_date, end_date, format_id likelihoods: run_id, variable_id, input_id machines: hostname managements: date, management_type methods: name, citation_id models: model_path pfts: name posteriors: pft_id priors: phylogeny, variable_id, distn, parama, paramb priors: phylogeny, variable_id, notes runs: (?) model_id, site_id, start_time, finish_time, parameter_list, ensemble_id sites: lat, lon, sitename species: scientificname (not genus, species because there may be multiple varieties) traits: site_id, specie_id, citation_id, cultivar_id, treatment_id, date, time, variable_id, entity_id, method_id, date_year, date_month, date_day, time_hour, time_minute treatments: for a given citation, name should be unique; for a given citation and site, there should be only one control users: (each of the following fields should be independently unique from other records) login email crypted_password salt apikey variables: name workflows: site_id, model_id, params, advanced_edit, start_date, end_date yields: site_id, specie_id, citation_id, cultivar_id, treatment_id, date, entity_id, method_id, date_year, date_month, date_day 14.6 Technical Note Database level constraints violates Ruby’s “Active Record” approach. The Rail Guide on Database Migrations suggests The Active Record way claims that intelligence belongs in your models, not in the database. As such, features such as triggers or foreign key constraints, which push some of that intelligence back into the database, are not heavily used. In order to add database constraints we moved from using db/schema.rb to db/structure.sql, so that the schema is stored in SQL rather than in Ruby. Given that the Ruby web application is only one of the ways in which we use the database, it seems reasonable to go with the SQL database-level constraints. The db/structure.sql approach is more straightforward, allows the database to exist independently of its Rails framework, and provides more flexibility. "],
["modifying-the-betydb-schema.html", "15 Modifying the BETYdb schema 15.1 Troubleshooting", " 15 Modifying the BETYdb schema Changes to the Bety schema happen through the Ruby on Rails database migration system. Here is a detailed guide on database migration for Ruby on Rails. What follows is a lightning guide to the essential steps. If you have not done so already, git clone the Bety repository. If you are on the VM, it should already be present in ~/bety. cd into the bety repository and update to the latest version with git pull. Make sure all Ruby gems are up to date. Running bundle check should do a quick check. If anything is out of date, update with bundle install --path vendor/bundle. (Adding the --path argument is strongly recommended to isolate these gems from the system install.) If this throws an error, see Troubleshooting below. Check the config/database.yml file to make sure that database parameters are set correctly. If you have multiple instances of Bety installed (e.g. development, production), adjust parameters accordingly. You can name each database environment whatever you want, but this guide assumes you are working with the production configuration (the default on the VM). The default VM configuration should look like this: production: adapter: postgis encoding: utf-8 reconnect: false database: bety pool: 5 username: bety password: bety Update the Bety database itself with the latest migrations by running bundle exec rake db:migrate RAILS_ENV=production (if you are using a different BETY instance, change production to whatever you are working on). If this command exits silently, then your bety instance is up to date. If it throws an error, see Troubleshooting below. Modifying the database involves adding new Ruby scripts to the db/migrate directory. In a nutshell, each migration describes a database revision (up – how to make the change) and its inverse (down – how to undo the change). Here is an example that adds a new workflow_id column to the ensembles table. class AddWorkflowIdToEnsembles &lt; ActiveRecord::Migration def self.up add_column :ensembles, :workflow_id, :integer end def self.down remove_column :ensembles, :workflow_id end end Here is another example that runs SQL code directly to add a constraint on a column in a table: class AddGeometryConstraint &lt; ActiveRecord::Migration def self.up execute %q{ ALTER TABLE public.sites ADD CONSTRAINT enforce_valid_geom CHECK (st_isvalid(geometry)) } end def self.down execute %q{ ALTER TABLE public.sites DROP CONSTRAINT enforce_valid_geom } end end There are lots of examples of previous migrations in this directory that can be used for reference. Database operations can be performed by passing SQL queries directly to an execute %q{&lt;YOUR QUERY HERE&gt;} statement, or through Ruby helper commands like change_column. Although you can name migrations whatever you want, because they are run in numerical-alphabetical order, the convention is to prefix your script with the current year, month, day, hour, minute, and second (you can generate this string by running date +%Y%m%d%H%M%S on the command line). Alternatively, a command like the following can be used to automatically generate a properly named file in the appropriate place: bundle exec rails generate migration MyNewMigration. To apply the new database changes, re-run bundle exec rake db:migrate RAILS_ENV=production from the bety repository root directory. To undo changes, use the db:rollback task (i.e. bundle exec rake db:rollback RAILS_ENV=production). Each call of db:rollback will undo one migration. Optionally, if you want to make multiple changes, add the STEP=n (e.g. STEP=3) flag to undo the last n migrations. If you want to modify the last migration, you can use the shortcut task db:rollback:redo (shorthand for db:rollback, then db:migrate). 15.1 Troubleshooting Error related to pg_dump non-existent option -i This is a bug the results from versions mismatches between Rails and Postgres. The correct solution is to update to Rails 2.4.6 or greater. The simpler solution is to manually grep through the vendor/bundle folder in your Bety instance, searching for instances of pg_dump and manually remove the -i arguments. This should only be in a few (~3) files. Before making these manual changes, be sure to run bundle install --path vendor/bundle to make sure you are modifying the most up-to-date gems. Otherwise, your changes will be overwritten. There is no need to re-run bundle install or any other command after these changes – they should propagate to the Rails app immediately and automatically. For reference, see this Stack Overflow question. Error related to “can’t activate …already activated” This is related to mismatches between the “installed” and required versions of a gem, or a mismatch between a gem’s version and the version expected by its dependencies. The basic solution is to uninstall the offending gem with bundle exec gem uninstall &lt;gem&gt; 10 and then re-install with bundle install --path vendor/bundle. If this doesn’t work, you may have to rm -rf the entire vendor/bundle directory and then re-install all gems with bundle install --path vendor/bundle. For reference, see this Stack Overflow question. Note that this command may throw an error like “undefined method ‘delete’ for bundler”. This is normal, and the gem was actually uninstalled.↩ "],
["issuing-a-new-release.html", "16 Issuing a New Release 16.1 Writing release notes 16.2 Upgrading the canonical BETYdb Rails site12 16.3 Upgrading other production sites 16.4 Finishing the release", " 16 Issuing a New Release From time to time, or whenever an important and needed code change is made, the principle maintainer of the BETYdb Rails application should issue a new release and upgrade all of the sites under his or her purview.11 In what follows, we delineate the key steps in this process. 16.1 Writing release notes Begin a new release by visiting the Web page https://github.com/PecanProject/bety/releases and clicking the Draft a new release button. The begin writing release notes in the large textarea box. The release notes should begin with a one-line summary of the release, written as a level-one heading (that is, with one “#” mark flush left). Follow this with a paragraph describing the release in slightly greater detail. Subsequent sections should summarize new features, bug fixes, and give some instruction to site maintainers on doing an upgrade to the new release. An easy way to begin writing release notes is to use an earlier version’s release notes (perhaps the notes from the previous one) as a template. Just click on the Releases link, click the Edit button of the release you choose to be you model, copy the text from the description section to the clipboard, and paste it into the description section for the release you are creating. Then change the text of each section as appropriate. To remind oneself of what changes to the code have been made since the previous release, you can examine the Git log content starting with the previous release using (for example) the command git log betydb_x.xx..master --stat (Here, betydb_x.xx is assumed to be the tag name for the previous release. The --stat flag is used to include a list of each file that was changed in each update.) Once the release notes are written, it remains only to fill in the release title and tag name text boxes and click the Publish Release button. But these final steps should be delayed until at least the primary site, https://www.betydb.org, has been upgraded, especially if the release involves a database migration. We give more details about this below. For now, just click the Save draft button to ensure your release notes don’t disappear. 16.2 Upgrading the canonical BETYdb Rails site12 Note: Although these instructions are specific to the primary production site, https://www.betydb.org, upgrading the beta site before upgrading the production site is highly recommended. If there are serious problems with the pending release version, it is much easier if they are found while upgrading a test version of the site so as not to have to try to back out of an upgrade to the production site. Moreover, upgrading the beta site can serve as a trial run for upgrading the production site. Note the following modification of the steps below when upgrading the beta site: After logging in to ebi-forecast, cd to /usr/local/beta rather than /usr/local/ebi. Making a backup copy of the database is unnecessary. Important If a migration is done, do not commit the updated structure.sql to the Git repository. It is the structure of the canonical copy of the database—ebi_production—that we want to document. While it is likely that the structure of the beta site’s database and the structure of the production site’s database are identical, it is best not to rely on this. Here are the steps required to upgrade the primary BETYdb Rails site to a newly-released version.13 These step are roughly the same for all the sites to be upgraded, but there are some slight differences, which we shall make note of where appropriate. Log in to the host machine ebi-forecast.igb.illinois.edu: ssh -X ebi-forecast.igb.illinois.edu The -X flag is needed if you intend to run the JavaScript-based RSpec tests on the host site (highly recommended). Go to the Rails root directory for the EBI site: cd /usr/local/ebi Check the git status to be sure the copy is “clean”: git status Generally there shouldn’t be any modified files and you should be on the master branch.14 Get the latest code from Github: git pull In rare cases, it may be that you need to release and deploy a version of the code other than the head of the master branch. This should be avoided if at all possible, especially if the release contains one or more migrations: it complicates incorporating an up-to-date version of the structure.sql into the release. Note that we tag releases AFTER deploying them, so we can’t use the release tag as the git reference. git checkout &lt;git reference to version being deployed&gt; Check the gem bundle and install new Gems if needed: bundle check If the the bundle contains uninstalled Gems, run this: bundle install Check for pending migrations and if needed, migrate the database: bundle exec rake db:migrate:status RAILS_ENV=production If there are no pending migrations, skip to the testing step. Make a backup copy of the database: pg_dump ebi_production &gt; [some suitable directory]/ebi_production.psql Generally, after the dump file has been created, I rename it to include the timestamp information in the file name: ebi_production_YYYYMMDDhhmm.psql. This way multiple dump files can be stored in the same directory.) Perform the pending migrations: bundle exec rake db:migrate RAILS_ENV=production It is especially important to dump the database if any of the pending migrations will delete data! Generate an up-to-date copy of db/structure.sql15 and check it in:16 bundle exec rake db:structure:dump RAILS_ENV=production git add db/structure.sql git commit git push Run automated tests: bundle exec rake db:test:prepare bundle exec rake db:fixtures:load RAILS_ENV=test bundle exec rspec -t ~js bundle exec rspec -t js The two rspec lines can be combined (just rspec), but I generally like to run the tests that don’t require a JavaScript driver first. They are much faster. Note that running the tests that do require a JavaScript driver need an X server to be running. In other words, use the -X option when ssh-ing into the production server. For more information about automated tests, see Automated Tests. If the tests pass, restart the Rails server: touch tmp/restart.txt Visit the updated site in a browser. This is to ensure the site is up and running. You may also wish to check some of the changes the upgrade is meant to implement to make sure they are working as expected. 16.3 Upgrading other production sites The steps for upgrading other production sites is largely the same as for the primary site https://www.betydb.org. [To do: add details] 16.4 Finishing the release Now that the release has been deployed, you can finish the formal release on GitHub. Go to the releases list at https://github.com/PecanProject/bety/releases and click on the draft that you started earlier. Give the release a title of the form “BETYdb X.XX” or “BETYdb X.XX.XX” and a Tag version identifier of the form “betydb_X.XX” (or “betydb_X.XX.XX”) and click the Publish release button. (See Version Numbering below.) I usually announce a new release on the Gitter chat page for BETYdb at https://gitter.im/PecanProject/bety?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge. Include a link to the release notes in your announcement. 16.4.1 Version Numbering We loosely follow semantic versioning. Any tag of the form betydb_x.x or betydb_x.x.x refers to a version that has been tested and deployed. Changes in the first or second digit of the version number mark some significant change. For example, the change to major version number 2.x marks the change to a new user interface. As of this writing these include deployments at https://www.betydb.org/, https://terra-mepp.illinois.edu/bety, https://terraref.ncsa.illinois.edu/bety/, and https://terraref.ncsa.illinois.edu/bety-test/. https://www.betydb.org/ is considered the canonical copy.↩ As of this writing, the primary or canonical site is the one on ebi-forecast.igb.illinois.edu at the URL https://www.betydb.org/. We call it canonical both because it was first, because it is site 0 in the site numbering scheme, but mainly because it is the site we use when generating updates to the structure.sql file, which itself is considered the canonical definition of the BETYdb database schema.↩ By newly released version, we actually mean the version that is about to be released, because as noted, we recommend not releasing a new version until at least the primary site has been upgraded.↩ In general, there will be some untracked files. The untracked files that should be present—database.yml for example—should be mentioned in a .gitignore file so that they don’t show up in the git status output. But the .gitignore files are not (at the time of this writing) up to date. Moreover, there may on occasion be intentionally modified files—for example, if an urgent fix was needed for a particular site before a bona fide release was possible. In these cases, it is best to save a copy of the modified file, revert the original, do the Git update, and then check if any changes from the saved copy need to be merged in. (Delete the copy when you are done with it.) In many cases, the custom changes will match the changes in the release.↩ Note that we no longer use the schema.rb file (see https://github.com/PecanProject/bety/issues/44). The structure.sql files allow for complete documentation of the database structure, including features that (by default) are not expressible in the schema.rb file. structure.sql is the canonical specification of the complete database schema, the schema which the Rails code is meant to be run against.↩ In point of fact, performing a migration of the production database should automatically generate an up-to-date version of db/structure.sql, so the first line in this sequence is not strictly necessary.↩ "],
["release-notes-template.html", "Release Notes Template", " Release Notes Template [one line summary] [full summary] ## Changes Pertinent to PEcAn Users (if applicable) **_Administrators need to do a database migration._** (if applicable) See &quot;Database Changes&quot; below. ## Summary of Changes ### New Features #### [feature 1] [explanation] #### [feature 2] [explanation] ... ### Bug Fixes #### [fix 1] [explanation] #### [fix 2] [explanation] ... ## Steps Needed for Upgrade ### Database Changes (if applicable) **_Administrators need to do database migrations!_** [description of migrations] The database version for this release is [migration id]. ### [special changes, if any] [explanation] ### Gem Installation (if applicable) **_Administrators need to run the bundler to install [[[several] new Ruby Gems] (and) [updated versions of existing ones]]._** [special instructions, if any, including minimizing installation for non-developers] ## Status of RSpec Tests ### All tests continue to pass when run in the default environment and can be run using the command ``` bundle exec rspec ``` Complete instructions for setting up the test database and running the RSpec tests are on the Wiki page at https://github.com/PecanProject/bety/wiki/Automated-Tests "]
]
